{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "import typing\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gym\n",
    "import gym_minigrid\n",
    "from gym_minigrid.wrappers import ImgObsWrapper\n",
    "from gym_minigrid.envs.numbertasks import NumberTaskType\n",
    "\n",
    "from stable_baselines3 import A2C, PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_env(env_id: str, **kwargs):\n",
    "    env = gym.make(env_id, **kwargs)\n",
    "    return Monitor(ImgObsWrapper(env))\n",
    "\n",
    "\n",
    "def _make_n_envs(env_id: str, n: int, seed: int, **kwargs):\n",
    "    return DummyVecEnv([lambda: _make_env(env_id, seed=seed + i, **kwargs) for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.56     |\n",
      "|    ep_rew_mean        | 0.481    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1479     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.891   |\n",
      "|    explained_variance | -0.00045 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.183   |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8        |\n",
      "|    ep_rew_mean        | 0.308    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1944     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.713   |\n",
      "|    explained_variance | 0.00991  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.017    |\n",
      "|    value_loss         | 0.0385   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.16     |\n",
      "|    ep_rew_mean        | 0.435    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2256     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.824   |\n",
      "|    explained_variance | -0.0016  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.0807   |\n",
      "|    value_loss         | 0.074    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.49     |\n",
      "|    ep_rew_mean        | 0.428    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2291     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.546   |\n",
      "|    explained_variance | -0.00396 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0682   |\n",
      "|    value_loss         | 0.0528   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.17     |\n",
      "|    ep_rew_mean        | 0.483    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2313     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.737   |\n",
      "|    explained_variance | 0.00325  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.00287  |\n",
      "|    value_loss         | 0.0806   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.16     |\n",
      "|    ep_rew_mean        | 0.428    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2277     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.674   |\n",
      "|    explained_variance | 0.00218  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0905   |\n",
      "|    value_loss         | 0.0749   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.68     |\n",
      "|    ep_rew_mean        | 0.449    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2298     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.39    |\n",
      "|    explained_variance | 0.00682  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.0458  |\n",
      "|    value_loss         | 0.0759   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.64     |\n",
      "|    ep_rew_mean        | 0.376    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2054     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.702   |\n",
      "|    explained_variance | 0.00213  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0492  |\n",
      "|    value_loss         | 0.0843   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.62     |\n",
      "|    ep_rew_mean        | 0.438    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2061     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.706   |\n",
      "|    explained_variance | 0.0178   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0244  |\n",
      "|    value_loss         | 0.0369   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 36       |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.673   |\n",
      "|    explained_variance | -0.00977 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0593   |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.29     |\n",
      "|    ep_rew_mean     | 0.427    |\n",
      "| time/              |          |\n",
      "|    fps             | 2071     |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.7      |\n",
      "|    ep_rew_mean        | 0.446    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2110     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.26    |\n",
      "|    explained_variance | 0.0101   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0998   |\n",
      "|    value_loss         | 0.0726   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.47     |\n",
      "|    ep_rew_mean        | 0.515    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2143     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.742   |\n",
      "|    explained_variance | 0.0144   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.0108   |\n",
      "|    value_loss         | 0.0821   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.56     |\n",
      "|    ep_rew_mean        | 0.337    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2171     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.752   |\n",
      "|    explained_variance | -0.00989 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0195  |\n",
      "|    value_loss         | 0.0412   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.46     |\n",
      "|    ep_rew_mean        | 0.482    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2201     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.749   |\n",
      "|    explained_variance | 0.00294  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.11     |\n",
      "|    value_loss         | 0.111    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.96     |\n",
      "|    ep_rew_mean        | 0.535    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2221     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.13    |\n",
      "|    explained_variance | 0.0115   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 0.0559   |\n",
      "|    value_loss         | 0.115    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.32     |\n",
      "|    ep_rew_mean        | 0.397    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2239     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.21    |\n",
      "|    explained_variance | 0.00691  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.228   |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.88     |\n",
      "|    ep_rew_mean        | 0.416    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2259     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.816   |\n",
      "|    explained_variance | -0.0507  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.115   |\n",
      "|    value_loss         | 0.0573   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 9.31     |\n",
      "|    ep_rew_mean        | 0.436    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2275     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.401   |\n",
      "|    explained_variance | 0.0054   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0404   |\n",
      "|    value_loss         | 0.081    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.88     |\n",
      "|    ep_rew_mean        | 0.587    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2286     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.473   |\n",
      "|    explained_variance | 0.00909  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.109   |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.57 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2        |\n",
      "|    mean_reward        | 0.57     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.399   |\n",
      "|    explained_variance | 0.0113   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.00544 |\n",
      "|    value_loss         | 0.134    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53     |\n",
      "|    ep_rew_mean     | 0.611    |\n",
      "| time/              |          |\n",
      "|    fps             | 2293     |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.5      |\n",
      "|    ep_rew_mean        | 0.611    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2297     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.249   |\n",
      "|    explained_variance | 0.00379  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.107   |\n",
      "|    value_loss         | 0.168    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.44     |\n",
      "|    ep_rew_mean        | 0.669    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2299     |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.335   |\n",
      "|    explained_variance | 0.00905  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.0158  |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.29     |\n",
      "|    ep_rew_mean        | 0.809    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2292     |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 115000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.249   |\n",
      "|    explained_variance | -0.0489  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | 0.00266  |\n",
      "|    value_loss         | 0.0171   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.12     |\n",
      "|    ep_rew_mean        | 0.857    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2287     |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.192   |\n",
      "|    explained_variance | -0.00785 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | -0.00482 |\n",
      "|    value_loss         | 0.0629   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.8      |\n",
      "|    ep_rew_mean        | 0.819    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2274     |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 125000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.14    |\n",
      "|    explained_variance | 0.0169   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0359  |\n",
      "|    value_loss         | 0.046    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.89      |\n",
      "|    ep_rew_mean        | 0.891     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2185      |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 130000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0935   |\n",
      "|    explained_variance | 0.0334    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -0.000831 |\n",
      "|    value_loss         | 0.0164    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.28      |\n",
      "|    ep_rew_mean        | 0.881     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2171      |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 135000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.103    |\n",
      "|    explained_variance | 0.157     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -0.000512 |\n",
      "|    value_loss         | 0.000506  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.95     |\n",
      "|    ep_rew_mean        | 0.853    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2159     |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0298  |\n",
      "|    explained_variance | 0.0458   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.000112 |\n",
      "|    value_loss         | 0.0735   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.04     |\n",
      "|    ep_rew_mean        | 0.915    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2162     |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 67       |\n",
      "|    total_timesteps    | 145000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | -0.0227  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.0268  |\n",
      "|    value_loss         | 0.0335   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.92 +/- 0.02\n",
      "Episode length: 3.20 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3.2      |\n",
      "|    mean_reward        | 0.92     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0249  |\n",
      "|    explained_variance | 0.353    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -2.8e-07 |\n",
      "|    value_loss         | 0.000777 |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.92  is above the threshold 0.85\n",
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.6     |\n",
      "|    ep_rew_mean     | 0.26     |\n",
      "| time/              |          |\n",
      "|    fps             | 2635     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11          |\n",
      "|    ep_rew_mean          | 0.32        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1171        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013697277 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.000426   |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0117      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0501      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.67 +/- 0.44\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.665       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011379054 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0416      |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.0631      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.07     |\n",
      "|    ep_rew_mean     | 0.407    |\n",
      "| time/              |          |\n",
      "|    fps             | 1083     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.11       |\n",
      "|    ep_rew_mean          | 0.549      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1060       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 77         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01368534 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.88      |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.00897    |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    value_loss           | 0.071      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.95 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026282798 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0382     |\n",
      "|    value_loss           | 0.0729      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward 0.95  is above the threshold 0.85\n",
      "Using cpu device\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.59     |\n",
      "|    ep_rew_mean        | 0.426    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1252     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.109    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    value_loss         | 0.082    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.99     |\n",
      "|    ep_rew_mean        | 0.376    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1594     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.492   |\n",
      "|    explained_variance | 0.279    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0152  |\n",
      "|    value_loss         | 0.0403   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.81     |\n",
      "|    ep_rew_mean        | 0.677    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1817     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.697   |\n",
      "|    explained_variance | 0.833    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.011   |\n",
      "|    value_loss         | 0.023    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.77     |\n",
      "|    ep_rew_mean        | 0.545    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1951     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.557   |\n",
      "|    explained_variance | 0.361    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0572  |\n",
      "|    value_loss         | 0.0933   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.94     |\n",
      "|    ep_rew_mean        | 0.401    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2037     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.574   |\n",
      "|    explained_variance | 0.466    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.0566   |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.6      |\n",
      "|    ep_rew_mean        | 0.521    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2116     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.587   |\n",
      "|    explained_variance | 0.287    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.00401 |\n",
      "|    value_loss         | 0.102    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.31     |\n",
      "|    ep_rew_mean        | 0.582    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2174     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.65    |\n",
      "|    explained_variance | 0.507    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0114   |\n",
      "|    value_loss         | 0.0146   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.07     |\n",
      "|    ep_rew_mean        | 0.759    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2223     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.497   |\n",
      "|    explained_variance | 0.154    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.00213 |\n",
      "|    value_loss         | 0.105    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.55     |\n",
      "|    ep_rew_mean        | 0.691    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2260     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.613   |\n",
      "|    explained_variance | 0.0185   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.0418   |\n",
      "|    value_loss         | 0.0838   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 5.80 +/- 10.10\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 5.8      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.421   |\n",
      "|    explained_variance | -0.0347  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.151   |\n",
      "|    value_loss         | 0.122    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.7      |\n",
      "|    ep_rew_mean     | 0.863    |\n",
      "| time/              |          |\n",
      "|    fps             | 2281     |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.2      |\n",
      "|    ep_rew_mean        | 0.755    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2285     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 24       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.47    |\n",
      "|    explained_variance | 0.0653   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.00686 |\n",
      "|    value_loss         | 0.0377   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.6      |\n",
      "|    ep_rew_mean        | 0.84     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2292     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.213   |\n",
      "|    explained_variance | -0.0918  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.00103 |\n",
      "|    value_loss         | 0.00253  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.98     |\n",
      "|    ep_rew_mean        | 0.789    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2307     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.317   |\n",
      "|    explained_variance | -0.0657  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.00625  |\n",
      "|    value_loss         | 0.00715  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.08     |\n",
      "|    ep_rew_mean        | 0.871    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2330     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.22    |\n",
      "|    explained_variance | 0.316    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.00123  |\n",
      "|    value_loss         | 0.00405  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.39     |\n",
      "|    ep_rew_mean        | 0.858    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2342     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.249   |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0111  |\n",
      "|    value_loss         | 0.0022   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.07     |\n",
      "|    ep_rew_mean        | 0.904    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2343     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.185   |\n",
      "|    explained_variance | 0.0327   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.00262 |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.45     |\n",
      "|    ep_rew_mean        | 0.877    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2348     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.116   |\n",
      "|    explained_variance | 0.0225   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.0576  |\n",
      "|    value_loss         | 0.0459   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.4       |\n",
      "|    ep_rew_mean        | 0.871     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2350      |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.114    |\n",
      "|    explained_variance | -0.228    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -0.000713 |\n",
      "|    value_loss         | 0.00201   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 0.897    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2359     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0993  |\n",
      "|    explained_variance | -0.00769 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -0.0225  |\n",
      "|    value_loss         | 0.0513   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 23.00 +/- 15.93\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 23       |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.086   |\n",
      "|    explained_variance | 0.0334   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0628  |\n",
      "|    value_loss         | 0.0742   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.05     |\n",
      "|    ep_rew_mean     | 0.807    |\n",
      "| time/              |          |\n",
      "|    fps             | 2356     |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.65     |\n",
      "|    ep_rew_mean        | 0.883    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2358     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.113   |\n",
      "|    explained_variance | 0.0155   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0024  |\n",
      "|    value_loss         | 0.00137  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.14     |\n",
      "|    ep_rew_mean        | 0.895    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2367     |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.118   |\n",
      "|    explained_variance | 0.0346   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | -0.107   |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.34     |\n",
      "|    ep_rew_mean        | 0.888    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2377     |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 115000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.202   |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.00814 |\n",
      "|    value_loss         | 0.00564  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.69     |\n",
      "|    ep_rew_mean        | 0.829    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2389     |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 50       |\n",
      "|    total_timesteps    | 120000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0598  |\n",
      "|    explained_variance | 0.0806   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00566  |\n",
      "|    value_loss         | 0.0246   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.16      |\n",
      "|    ep_rew_mean        | 0.912     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2395      |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 125000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00563  |\n",
      "|    explained_variance | 0.356     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | -1.16e-05 |\n",
      "|    value_loss         | 0.000652  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.34     |\n",
      "|    ep_rew_mean        | 0.833    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2400     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0435  |\n",
      "|    explained_variance | 0.237    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.000945 |\n",
      "|    value_loss         | 0.0179   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.59     |\n",
      "|    ep_rew_mean        | 0.91     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2406     |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0799  |\n",
      "|    explained_variance | 0.451    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.00112 |\n",
      "|    value_loss         | 0.00328  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.06      |\n",
      "|    ep_rew_mean        | 0.895     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2411      |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 140000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0364   |\n",
      "|    explained_variance | 0.324     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | -0.000145 |\n",
      "|    value_loss         | 0.00139   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.2      |\n",
      "|    ep_rew_mean        | 0.911    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 145000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.115   |\n",
      "|    explained_variance | 0.241    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.00728 |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3.2      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0938  |\n",
      "|    explained_variance | 0.294    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.00421 |\n",
      "|    value_loss         | 0.000886 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.14     |\n",
      "|    ep_rew_mean     | 0.922    |\n",
      "| time/              |          |\n",
      "|    fps             | 2417     |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.84     |\n",
      "|    ep_rew_mean        | 0.866    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2414     |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 155000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0766  |\n",
      "|    explained_variance | 0.195    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.00156  |\n",
      "|    value_loss         | 0.00123  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 6.35      |\n",
      "|    ep_rew_mean        | 0.81      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 160000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00518  |\n",
      "|    explained_variance | -0.00905  |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | -4.66e-05 |\n",
      "|    value_loss         | 0.0416    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.82      |\n",
      "|    ep_rew_mean        | 0.92      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2417      |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 165000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0187   |\n",
      "|    explained_variance | 0.571     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | -4.37e-05 |\n",
      "|    value_loss         | 0.000306  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.53     |\n",
      "|    ep_rew_mean        | 0.836    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2420     |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0396  |\n",
      "|    explained_variance | 0.0615   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.0279  |\n",
      "|    value_loss         | 0.0344   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.49     |\n",
      "|    ep_rew_mean        | 0.903    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2423     |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 175000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.123   |\n",
      "|    explained_variance | -0.288   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.00203 |\n",
      "|    value_loss         | 0.00224  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.12     |\n",
      "|    ep_rew_mean        | 0.884    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2407     |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0548  |\n",
      "|    explained_variance | 0.183    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.0153  |\n",
      "|    value_loss         | 0.00985  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.22      |\n",
      "|    ep_rew_mean        | 0.902     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2395      |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 185000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0275   |\n",
      "|    explained_variance | 0.16      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | -0.000298 |\n",
      "|    value_loss         | 0.00186   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.94     |\n",
      "|    ep_rew_mean        | 0.775    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2397     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.18    |\n",
      "|    explained_variance | 0.0114   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.0381  |\n",
      "|    value_loss         | 0.0801   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.14     |\n",
      "|    ep_rew_mean        | 0.886    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2400     |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 195000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0194  |\n",
      "|    explained_variance | 0.451    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.00121  |\n",
      "|    value_loss         | 0.00145  |\n",
      "------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 15.80 +/- 16.50\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 15.8     |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0251  |\n",
      "|    explained_variance | 0.531    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.00278 |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7      |\n",
      "|    ep_rew_mean     | 0.904    |\n",
      "| time/              |          |\n",
      "|    fps             | 2401     |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.88     |\n",
      "|    ep_rew_mean        | 0.833    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2402     |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 205000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0179  |\n",
      "|    explained_variance | 0.0162   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.00333 |\n",
      "|    value_loss         | 0.0548   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.76     |\n",
      "|    ep_rew_mean        | 0.903    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2403     |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0175  |\n",
      "|    explained_variance | 0.715    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 5.6e-05  |\n",
      "|    value_loss         | 0.000239 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.49     |\n",
      "|    ep_rew_mean        | 0.894    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2404     |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 89       |\n",
      "|    total_timesteps    | 215000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0804  |\n",
      "|    explained_variance | 0.0189   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.00223 |\n",
      "|    value_loss         | 0.00908  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.54     |\n",
      "|    ep_rew_mean        | 0.877    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2407     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 91       |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.121   |\n",
      "|    explained_variance | -0.754   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0123  |\n",
      "|    value_loss         | 0.00218  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.21      |\n",
      "|    ep_rew_mean        | 0.91      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2408      |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 225000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0144   |\n",
      "|    explained_variance | 0.625     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | -4.71e-05 |\n",
      "|    value_loss         | 0.000418  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.69      |\n",
      "|    ep_rew_mean        | 0.908     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2409      |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 230000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0785   |\n",
      "|    explained_variance | 0.352     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -7.38e-06 |\n",
      "|    value_loss         | 0.00101   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.25     |\n",
      "|    ep_rew_mean        | 0.9      |\n",
      "| time/                 |          |\n",
      "|    fps                | 2410     |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 97       |\n",
      "|    total_timesteps    | 235000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0095  |\n",
      "|    explained_variance | 0.5      |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | 3.48e-05 |\n",
      "|    value_loss         | 0.000822 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.35      |\n",
      "|    ep_rew_mean        | 0.908     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2412      |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 240000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0697   |\n",
      "|    explained_variance | 0.351     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | -0.000654 |\n",
      "|    value_loss         | 0.00157   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 4.12      |\n",
      "|    ep_rew_mean        | 0.887     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 245000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0204   |\n",
      "|    explained_variance | -0.0619   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -5.56e-05 |\n",
      "|    value_loss         | 0.00289   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.40 +/- 0.92\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.4       |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 250000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0358   |\n",
      "|    explained_variance | 0.514     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -0.000187 |\n",
      "|    value_loss         | 0.000488  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.83     |\n",
      "|    ep_rew_mean     | 0.929    |\n",
      "| time/              |          |\n",
      "|    fps             | 2419     |\n",
      "|    iterations      | 5000     |\n",
      "|    time_elapsed    | 103      |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.36     |\n",
      "|    ep_rew_mean        | 0.818    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2417     |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 255000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.196   |\n",
      "|    explained_variance | 0.122    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | -0.0103  |\n",
      "|    value_loss         | 0.0128   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.7      |\n",
      "|    ep_rew_mean        | 0.923    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2418     |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0248  |\n",
      "|    explained_variance | 0.0489   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | -0.0836  |\n",
      "|    value_loss         | 0.0171   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.36     |\n",
      "|    ep_rew_mean        | 0.825    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2419     |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 109      |\n",
      "|    total_timesteps    | 265000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.016   |\n",
      "|    explained_variance | 0.542    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | -0.00208 |\n",
      "|    value_loss         | 0.00423  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.96     |\n",
      "|    ep_rew_mean        | 0.909    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2421     |\n",
      "|    iterations         | 5400     |\n",
      "|    time_elapsed       | 111      |\n",
      "|    total_timesteps    | 270000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.2     |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5399     |\n",
      "|    policy_loss        | -0.0292  |\n",
      "|    value_loss         | 0.0297   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.69     |\n",
      "|    ep_rew_mean        | 0.889    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2424     |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 275000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0728  |\n",
      "|    explained_variance | 0.461    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 0.00691  |\n",
      "|    value_loss         | 0.00257  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.34     |\n",
      "|    ep_rew_mean        | 0.828    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2426     |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 280000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.02    |\n",
      "|    explained_variance | -0.0176  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | -0.00498 |\n",
      "|    value_loss         | 0.048    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.81     |\n",
      "|    ep_rew_mean        | 0.876    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2426     |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 117      |\n",
      "|    total_timesteps    | 285000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0369  |\n",
      "|    explained_variance | 0.0137   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -0.0192  |\n",
      "|    value_loss         | 0.06     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.56     |\n",
      "|    ep_rew_mean        | 0.892    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2428     |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00214 |\n",
      "|    explained_variance | 0.686    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 1.75e-05 |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.73     |\n",
      "|    ep_rew_mean        | 0.878    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 295000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.122   |\n",
      "|    explained_variance | 0.334    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 0.000122 |\n",
      "|    value_loss         | 0.00091  |\n",
      "------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.40 +/- 0.92\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3.4      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 300000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.129   |\n",
      "|    explained_variance | 0.186    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -0.00192 |\n",
      "|    value_loss         | 0.00176  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.32     |\n",
      "|    ep_rew_mean     | 0.874    |\n",
      "| time/              |          |\n",
      "|    fps             | 2434     |\n",
      "|    iterations      | 6000     |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.63     |\n",
      "|    ep_rew_mean        | 0.828    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2432     |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 305000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00595 |\n",
      "|    explained_variance | 0.209    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 7.4e-05  |\n",
      "|    value_loss         | 0.0075   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.92      |\n",
      "|    ep_rew_mean        | 0.908     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2432      |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 310000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0369   |\n",
      "|    explained_variance | 0.642     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | -0.000256 |\n",
      "|    value_loss         | 0.000615  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.89     |\n",
      "|    ep_rew_mean        | 0.88     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 315000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.0196   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | -0.0645  |\n",
      "|    value_loss         | 0.0829   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.01      |\n",
      "|    ep_rew_mean        | 0.925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0194   |\n",
      "|    explained_variance | 0.671     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -1.61e-05 |\n",
      "|    value_loss         | 0.000365  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.89      |\n",
      "|    ep_rew_mean        | 0.928     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2431      |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 325000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00969  |\n",
      "|    explained_variance | 0.386     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -5.28e-05 |\n",
      "|    value_loss         | 0.000601  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.72     |\n",
      "|    ep_rew_mean        | 0.852    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0458  |\n",
      "|    explained_variance | 0.00787  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 0.001    |\n",
      "|    value_loss         | 0.0199   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.84     |\n",
      "|    ep_rew_mean        | 0.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2432     |\n",
      "|    iterations         | 6700     |\n",
      "|    time_elapsed       | 137      |\n",
      "|    total_timesteps    | 335000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0348  |\n",
      "|    explained_variance | 0.599    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6699     |\n",
      "|    policy_loss        | 1.43e-05 |\n",
      "|    value_loss         | 0.000684 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.75     |\n",
      "|    ep_rew_mean        | 0.896    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2434     |\n",
      "|    iterations         | 6800     |\n",
      "|    time_elapsed       | 139      |\n",
      "|    total_timesteps    | 340000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00763 |\n",
      "|    explained_variance | 0.000589 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6799     |\n",
      "|    policy_loss        | 5.42e-06 |\n",
      "|    value_loss         | 0.00293  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.92      |\n",
      "|    ep_rew_mean        | 0.908     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2434      |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 345000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0104   |\n",
      "|    explained_variance | 0.323     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | -6.56e-05 |\n",
      "|    value_loss         | 0.00109   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 2.80 +/- 0.98\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2.8       |\n",
      "|    mean_reward        | 0.19      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 350000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.012    |\n",
      "|    explained_variance | 0.375     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | -5.23e-05 |\n",
      "|    value_loss         | 0.00074   |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.98     |\n",
      "|    ep_rew_mean     | 0.926    |\n",
      "| time/              |          |\n",
      "|    fps             | 2432     |\n",
      "|    iterations      | 7000     |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 350000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.92      |\n",
      "|    ep_rew_mean        | 0.927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2429      |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 355000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000549 |\n",
      "|    explained_variance | 0.825     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | -3.91e-07 |\n",
      "|    value_loss         | 0.000179  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 4.27      |\n",
      "|    ep_rew_mean        | 0.876     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2428      |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 360000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0216   |\n",
      "|    explained_variance | 0.218     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | -0.000187 |\n",
      "|    value_loss         | 0.00304   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.59      |\n",
      "|    ep_rew_mean        | 0.76      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2429      |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 365000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0251   |\n",
      "|    explained_variance | -0.875    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -5.15e-05 |\n",
      "|    value_loss         | 0.000344  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.13      |\n",
      "|    ep_rew_mean        | 0.912     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2429      |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 370000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0264   |\n",
      "|    explained_variance | 0.521     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -0.000299 |\n",
      "|    value_loss         | 0.000293  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.09      |\n",
      "|    ep_rew_mean        | 0.923     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2427      |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 375000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0108   |\n",
      "|    explained_variance | 0.626     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -5.42e-05 |\n",
      "|    value_loss         | 0.000325  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.33     |\n",
      "|    ep_rew_mean        | 0.907    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2426     |\n",
      "|    iterations         | 7600     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 380000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0244  |\n",
      "|    explained_variance | 0.00229  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -0.022   |\n",
      "|    value_loss         | 0.0329   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.96      |\n",
      "|    ep_rew_mean        | 0.926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2427      |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 385000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0263   |\n",
      "|    explained_variance | 0.735     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -0.000125 |\n",
      "|    value_loss         | 0.000253  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.05     |\n",
      "|    ep_rew_mean        | 0.905    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2427     |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 390000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.155   |\n",
      "|    explained_variance | 0.435    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | -0.00414 |\n",
      "|    value_loss         | 0.00164  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.92     |\n",
      "|    ep_rew_mean        | 0.917    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2428     |\n",
      "|    iterations         | 7900     |\n",
      "|    time_elapsed       | 162      |\n",
      "|    total_timesteps    | 395000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0672  |\n",
      "|    explained_variance | 0.592    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 7899     |\n",
      "|    policy_loss        | 0.00129  |\n",
      "|    value_loss         | 0.000722 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.2       |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 400000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00246  |\n",
      "|    explained_variance | 0.618     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -1.17e-05 |\n",
      "|    value_loss         | 0.000287  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.07     |\n",
      "|    ep_rew_mean     | 0.923    |\n",
      "| time/              |          |\n",
      "|    fps             | 2428     |\n",
      "|    iterations      | 8000     |\n",
      "|    time_elapsed    | 164      |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 4.7       |\n",
      "|    ep_rew_mean        | 0.869     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2426      |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.014    |\n",
      "|    explained_variance | -0.022    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | -0.000996 |\n",
      "|    value_loss         | 0.0957    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.13     |\n",
      "|    ep_rew_mean        | 0.922    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2426     |\n",
      "|    iterations         | 8200     |\n",
      "|    time_elapsed       | 168      |\n",
      "|    total_timesteps    | 410000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0453  |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8199     |\n",
      "|    policy_loss        | -0.00392 |\n",
      "|    value_loss         | 0.000709 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.13     |\n",
      "|    ep_rew_mean        | 0.885    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2426     |\n",
      "|    iterations         | 8300     |\n",
      "|    time_elapsed       | 171      |\n",
      "|    total_timesteps    | 415000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00948 |\n",
      "|    explained_variance | 0.0414   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8299     |\n",
      "|    policy_loss        | -0.00085 |\n",
      "|    value_loss         | 0.0165   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.55     |\n",
      "|    ep_rew_mean        | 0.874    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2427     |\n",
      "|    iterations         | 8400     |\n",
      "|    time_elapsed       | 173      |\n",
      "|    total_timesteps    | 420000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.204   |\n",
      "|    explained_variance | 0.243    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8399     |\n",
      "|    policy_loss        | -0.00586 |\n",
      "|    value_loss         | 0.0019   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.62     |\n",
      "|    ep_rew_mean        | 0.769    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2428     |\n",
      "|    iterations         | 8500     |\n",
      "|    time_elapsed       | 174      |\n",
      "|    total_timesteps    | 425000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.012   |\n",
      "|    explained_variance | 0.0512   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8499     |\n",
      "|    policy_loss        | -0.00011 |\n",
      "|    value_loss         | 0.0511   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 6.73      |\n",
      "|    ep_rew_mean        | 0.824     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2431      |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 430000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00556  |\n",
      "|    explained_variance | 0.114     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | -5.97e-06 |\n",
      "|    value_loss         | 0.00663   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.31     |\n",
      "|    ep_rew_mean        | 0.76     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2432     |\n",
      "|    iterations         | 8700     |\n",
      "|    time_elapsed       | 178      |\n",
      "|    total_timesteps    | 435000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0468  |\n",
      "|    explained_variance | 0.0267   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8699     |\n",
      "|    policy_loss        | -0.00899 |\n",
      "|    value_loss         | 0.0493   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.84     |\n",
      "|    ep_rew_mean        | 0.873    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2433     |\n",
      "|    iterations         | 8800     |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 440000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.498    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 8799     |\n",
      "|    policy_loss        | 0.0058   |\n",
      "|    value_loss         | 0.00309  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.03      |\n",
      "|    ep_rew_mean        | 0.924     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2433      |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 445000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0266   |\n",
      "|    explained_variance | 0.421     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -0.000196 |\n",
      "|    value_loss         | 0.000558  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.10 +/- 0.28\n",
      "Episode length: 3.40 +/- 0.92\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.4       |\n",
      "|    mean_reward        | 0.095     |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 450000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00537  |\n",
      "|    explained_variance | 0.792     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -1.66e-05 |\n",
      "|    value_loss         | 0.000216  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.18     |\n",
      "|    ep_rew_mean     | 0.911    |\n",
      "| time/              |          |\n",
      "|    fps             | 2433     |\n",
      "|    iterations      | 9000     |\n",
      "|    time_elapsed    | 184      |\n",
      "|    total_timesteps | 450000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.79      |\n",
      "|    ep_rew_mean        | 0.93      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 455000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00946  |\n",
      "|    explained_variance | 0.69      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | -1.22e-05 |\n",
      "|    value_loss         | 0.000258  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.19     |\n",
      "|    ep_rew_mean        | 0.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 460000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00364 |\n",
      "|    explained_variance | 0.776    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 1.46e-05 |\n",
      "|    value_loss         | 0.000177 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.5      |\n",
      "|    ep_rew_mean        | 0.887    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2428     |\n",
      "|    iterations         | 9300     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 465000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0728  |\n",
      "|    explained_variance | 0.604    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9299     |\n",
      "|    policy_loss        | -0.00255 |\n",
      "|    value_loss         | 0.00083  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.33      |\n",
      "|    ep_rew_mean        | 0.917     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2428      |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 193       |\n",
      "|    total_timesteps    | 470000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0242   |\n",
      "|    explained_variance | 0.596     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -3.89e-05 |\n",
      "|    value_loss         | 0.000422  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.1      |\n",
      "|    ep_rew_mean        | 0.913    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 9500     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 475000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0104  |\n",
      "|    explained_variance | 0.748    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | 7.05e-05 |\n",
      "|    value_loss         | 0.000194 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.03     |\n",
      "|    ep_rew_mean        | 0.924    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 9600     |\n",
      "|    time_elapsed       | 197      |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.067   |\n",
      "|    explained_variance | 0.56     |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9599     |\n",
      "|    policy_loss        | -0.00464 |\n",
      "|    value_loss         | 0.000518 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.1      |\n",
      "|    ep_rew_mean        | 0.923    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2429     |\n",
      "|    iterations         | 9700     |\n",
      "|    time_elapsed       | 199      |\n",
      "|    total_timesteps    | 485000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0128  |\n",
      "|    explained_variance | 0.634    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9699     |\n",
      "|    policy_loss        | 7.38e-05 |\n",
      "|    value_loss         | 0.000542 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.56     |\n",
      "|    ep_rew_mean        | 0.848    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 9800     |\n",
      "|    time_elapsed       | 201      |\n",
      "|    total_timesteps    | 490000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00701 |\n",
      "|    explained_variance | 0.536    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9799     |\n",
      "|    policy_loss        | 2e-05    |\n",
      "|    value_loss         | 0.00188  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.07     |\n",
      "|    ep_rew_mean        | 0.867    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2432     |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 203      |\n",
      "|    total_timesteps    | 495000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0392  |\n",
      "|    explained_variance | 0.136    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | 0.000447 |\n",
      "|    value_loss         | 0.0193   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.10 +/- 0.28\n",
      "Episode length: 2.80 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.8      |\n",
      "|    mean_reward        | 0.095    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 500000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.16    |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9999     |\n",
      "|    policy_loss        | -0.0116  |\n",
      "|    value_loss         | 0.00151  |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.23     |\n",
      "|    ep_rew_mean     | 0.883    |\n",
      "| time/              |          |\n",
      "|    fps             | 2431     |\n",
      "|    iterations      | 10000    |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.86      |\n",
      "|    ep_rew_mean        | 0.881     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2429      |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 505000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.016    |\n",
      "|    explained_variance | 0.551     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -1.86e-05 |\n",
      "|    value_loss         | 0.00161   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.93      |\n",
      "|    ep_rew_mean        | 0.889     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2428      |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 510000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.046    |\n",
      "|    explained_variance | 0.434     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -0.000228 |\n",
      "|    value_loss         | 0.000591  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.78     |\n",
      "|    ep_rew_mean        | 0.931    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2428     |\n",
      "|    iterations         | 10300    |\n",
      "|    time_elapsed       | 212      |\n",
      "|    total_timesteps    | 515000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00898 |\n",
      "|    explained_variance | 0.6      |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 10299    |\n",
      "|    policy_loss        | 3.28e-05 |\n",
      "|    value_loss         | 0.00034  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.98     |\n",
      "|    ep_rew_mean        | 0.916    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 10400    |\n",
      "|    time_elapsed       | 213      |\n",
      "|    total_timesteps    | 520000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0524  |\n",
      "|    explained_variance | 0.35     |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 10399    |\n",
      "|    policy_loss        | -0.00157 |\n",
      "|    value_loss         | 0.00182  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.85      |\n",
      "|    ep_rew_mean        | 0.929     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2431      |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 525000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0367   |\n",
      "|    explained_variance | 0.622     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0.000486 |\n",
      "|    value_loss         | 0.000607  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.43     |\n",
      "|    ep_rew_mean        | 0.845    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 217      |\n",
      "|    total_timesteps    | 530000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.139   |\n",
      "|    explained_variance | 0.325    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -0.00186 |\n",
      "|    value_loss         | 0.00509  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.73      |\n",
      "|    ep_rew_mean        | 0.932     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 220       |\n",
      "|    total_timesteps    | 535000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0517   |\n",
      "|    explained_variance | 0.605     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -0.000589 |\n",
      "|    value_loss         | 0.000451  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.7      |\n",
      "|    ep_rew_mean        | 0.923    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 10800    |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 540000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0342  |\n",
      "|    explained_variance | 0.0357   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 10799    |\n",
      "|    policy_loss        | -0.0129  |\n",
      "|    value_loss         | 0.0171   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.17      |\n",
      "|    ep_rew_mean        | 0.921     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2431      |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 224       |\n",
      "|    total_timesteps    | 545000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0176   |\n",
      "|    explained_variance | 0.568     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -0.000106 |\n",
      "|    value_loss         | 0.000361  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.2       |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 550000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00765  |\n",
      "|    explained_variance | 0.694     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -9.03e-05 |\n",
      "|    value_loss         | 0.000382  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.9      |\n",
      "|    ep_rew_mean     | 0.927    |\n",
      "| time/              |          |\n",
      "|    fps             | 2431     |\n",
      "|    iterations      | 11000    |\n",
      "|    time_elapsed    | 226      |\n",
      "|    total_timesteps | 550000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.15     |\n",
      "|    ep_rew_mean        | 0.921    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 11100    |\n",
      "|    time_elapsed       | 228      |\n",
      "|    total_timesteps    | 555000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0285  |\n",
      "|    explained_variance | 0.572    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11099    |\n",
      "|    policy_loss        | -0.00444 |\n",
      "|    value_loss         | 0.000478 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.66     |\n",
      "|    ep_rew_mean        | 0.886    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2429     |\n",
      "|    iterations         | 11200    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 560000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.107   |\n",
      "|    explained_variance | 0.437    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11199    |\n",
      "|    policy_loss        | -0.00269 |\n",
      "|    value_loss         | 0.00164  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.94     |\n",
      "|    ep_rew_mean        | 0.917    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 11300    |\n",
      "|    time_elapsed       | 232      |\n",
      "|    total_timesteps    | 565000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.198   |\n",
      "|    explained_variance | -0.307   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11299    |\n",
      "|    policy_loss        | -0.00726 |\n",
      "|    value_loss         | 0.0012   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.41     |\n",
      "|    ep_rew_mean        | 0.835    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 11400    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 570000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0173  |\n",
      "|    explained_variance | 0.364    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | -0.00012 |\n",
      "|    value_loss         | 0.00349  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 8.32     |\n",
      "|    ep_rew_mean        | 0.782    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2431     |\n",
      "|    iterations         | 11500    |\n",
      "|    time_elapsed       | 236      |\n",
      "|    total_timesteps    | 575000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0228  |\n",
      "|    explained_variance | 0.145    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11499    |\n",
      "|    policy_loss        | 0.00148  |\n",
      "|    value_loss         | 0.0223   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.1       |\n",
      "|    ep_rew_mean        | 0.923     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 238       |\n",
      "|    total_timesteps    | 580000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00915  |\n",
      "|    explained_variance | 0.572     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -4.86e-05 |\n",
      "|    value_loss         | 0.000308  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.88      |\n",
      "|    ep_rew_mean        | 0.881     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 240       |\n",
      "|    total_timesteps    | 585000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00846  |\n",
      "|    explained_variance | 0.745     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -1.81e-05 |\n",
      "|    value_loss         | 0.000286  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.12     |\n",
      "|    ep_rew_mean        | 0.894    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2430     |\n",
      "|    iterations         | 11800    |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 590000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.114   |\n",
      "|    explained_variance | 0.354    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11799    |\n",
      "|    policy_loss        | -0.00254 |\n",
      "|    value_loss         | 0.000964 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.1       |\n",
      "|    ep_rew_mean        | 0.923     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2430      |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 244       |\n",
      "|    total_timesteps    | 595000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00502  |\n",
      "|    explained_variance | 0.581     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -2.78e-05 |\n",
      "|    value_loss         | 0.000348  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3.2      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 600000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.103   |\n",
      "|    explained_variance | 0.0258   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | 0.0021   |\n",
      "|    value_loss         | 0.0228   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.54     |\n",
      "|    ep_rew_mean     | 0.811    |\n",
      "| time/              |          |\n",
      "|    fps             | 2431     |\n",
      "|    iterations      | 12000    |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.97     |\n",
      "|    ep_rew_mean        | 0.926    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2429     |\n",
      "|    iterations         | 12100    |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 605000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0111  |\n",
      "|    explained_variance | 0.738    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12099    |\n",
      "|    policy_loss        | -4.2e-05 |\n",
      "|    value_loss         | 0.000293 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.13     |\n",
      "|    ep_rew_mean        | 0.812    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2429     |\n",
      "|    iterations         | 12200    |\n",
      "|    time_elapsed       | 251      |\n",
      "|    total_timesteps    | 610000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0182  |\n",
      "|    explained_variance | 0.285    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12199    |\n",
      "|    policy_loss        | 0.000649 |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.13      |\n",
      "|    ep_rew_mean        | 0.913     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2424      |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 253       |\n",
      "|    total_timesteps    | 615000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00463  |\n",
      "|    explained_variance | 0.736     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -1.48e-05 |\n",
      "|    value_loss         | 0.000212  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.37      |\n",
      "|    ep_rew_mean        | 0.851     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2417      |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 620000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.012    |\n",
      "|    explained_variance | -0.0254   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0.000151 |\n",
      "|    value_loss         | 0.0542    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.05     |\n",
      "|    ep_rew_mean        | 0.924    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2414     |\n",
      "|    iterations         | 12500    |\n",
      "|    time_elapsed       | 258      |\n",
      "|    total_timesteps    | 625000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0168  |\n",
      "|    explained_variance | 0.703    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12499    |\n",
      "|    policy_loss        | 7.42e-05 |\n",
      "|    value_loss         | 0.000273 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.17     |\n",
      "|    ep_rew_mean        | 0.856    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 12600    |\n",
      "|    time_elapsed       | 260      |\n",
      "|    total_timesteps    | 630000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.129   |\n",
      "|    explained_variance | 0.0121   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12599    |\n",
      "|    policy_loss        | -0.00469 |\n",
      "|    value_loss         | 0.0522   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.8      |\n",
      "|    ep_rew_mean        | 0.854    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 635000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0458  |\n",
      "|    explained_variance | 0.0193   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -0.00794 |\n",
      "|    value_loss         | 0.0745   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.09      |\n",
      "|    ep_rew_mean        | 0.923     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 264       |\n",
      "|    total_timesteps    | 640000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000644 |\n",
      "|    explained_variance | 0.71      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -1.44e-06 |\n",
      "|    value_loss         | 0.000204  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.16     |\n",
      "|    ep_rew_mean        | 0.912    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 266      |\n",
      "|    total_timesteps    | 645000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.132   |\n",
      "|    explained_variance | 0.226    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0.00142 |\n",
      "|    value_loss         | 0.000686 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.00 +/- 1.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3         |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 650000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000302 |\n",
      "|    explained_variance | 0.854     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -7.64e-07 |\n",
      "|    value_loss         | 0.000145  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.9      |\n",
      "|    ep_rew_mean     | 0.928    |\n",
      "| time/              |          |\n",
      "|    fps             | 2417     |\n",
      "|    iterations      | 13000    |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 650000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.97     |\n",
      "|    ep_rew_mean        | 0.916    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 13100    |\n",
      "|    time_elapsed       | 271      |\n",
      "|    total_timesteps    | 655000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0521  |\n",
      "|    explained_variance | 0.585    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13099    |\n",
      "|    policy_loss        | 7.83e-05 |\n",
      "|    value_loss         | 0.000437 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.84      |\n",
      "|    ep_rew_mean        | 0.929     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 273       |\n",
      "|    total_timesteps    | 660000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0228   |\n",
      "|    explained_variance | 0.5       |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -0.000148 |\n",
      "|    value_loss         | 0.000602  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.17      |\n",
      "|    ep_rew_mean        | 0.921     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 665000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00567  |\n",
      "|    explained_variance | 0.632     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -2.05e-05 |\n",
      "|    value_loss         | 0.00024   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.22     |\n",
      "|    ep_rew_mean        | 0.882    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 13400    |\n",
      "|    time_elapsed       | 277      |\n",
      "|    total_timesteps    | 670000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0153  |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13399    |\n",
      "|    policy_loss        | 0.000192 |\n",
      "|    value_loss         | 0.000492 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.03     |\n",
      "|    ep_rew_mean        | 0.924    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 13500    |\n",
      "|    time_elapsed       | 279      |\n",
      "|    total_timesteps    | 675000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00104 |\n",
      "|    explained_variance | 0.886    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13499    |\n",
      "|    policy_loss        | 4.44e-07 |\n",
      "|    value_loss         | 0.000128 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.03      |\n",
      "|    ep_rew_mean        | 0.915     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 281       |\n",
      "|    total_timesteps    | 680000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0241   |\n",
      "|    explained_variance | 0.728     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -0.000198 |\n",
      "|    value_loss         | 0.000237  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.04     |\n",
      "|    ep_rew_mean        | 0.915    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 13700    |\n",
      "|    time_elapsed       | 283      |\n",
      "|    total_timesteps    | 685000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0402  |\n",
      "|    explained_variance | 0.623    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13699    |\n",
      "|    policy_loss        | -0.00148 |\n",
      "|    value_loss         | 0.000513 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.07     |\n",
      "|    ep_rew_mean        | 0.914    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2416     |\n",
      "|    iterations         | 13800    |\n",
      "|    time_elapsed       | 285      |\n",
      "|    total_timesteps    | 690000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.215   |\n",
      "|    explained_variance | 0.432    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13799    |\n",
      "|    policy_loss        | -0.00192 |\n",
      "|    value_loss         | 0.000683 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.88     |\n",
      "|    ep_rew_mean        | 0.909    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2418     |\n",
      "|    iterations         | 13900    |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 695000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0589  |\n",
      "|    explained_variance | 0.0402   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13899    |\n",
      "|    policy_loss        | -0.0482  |\n",
      "|    value_loss         | 0.069    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.00 +/- 1.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3        |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 700000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0791  |\n",
      "|    explained_variance | 0.0215   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13999    |\n",
      "|    policy_loss        | -0.0305  |\n",
      "|    value_loss         | 0.0175   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.09     |\n",
      "|    ep_rew_mean     | 0.914    |\n",
      "| time/              |          |\n",
      "|    fps             | 2417     |\n",
      "|    iterations      | 14000    |\n",
      "|    time_elapsed    | 289      |\n",
      "|    total_timesteps | 700000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.11     |\n",
      "|    ep_rew_mean        | 0.922    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2417     |\n",
      "|    iterations         | 14100    |\n",
      "|    time_elapsed       | 291      |\n",
      "|    total_timesteps    | 705000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0368  |\n",
      "|    explained_variance | 0.587    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14099    |\n",
      "|    policy_loss        | -0.00283 |\n",
      "|    value_loss         | 0.000389 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 0.925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2417      |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 710000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0198   |\n",
      "|    explained_variance | 0.557     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -0.000156 |\n",
      "|    value_loss         | 0.000402  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.17     |\n",
      "|    ep_rew_mean        | 0.858    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2418     |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 295      |\n",
      "|    total_timesteps    | 715000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.122   |\n",
      "|    explained_variance | 0.0352   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0.0011  |\n",
      "|    value_loss         | 0.00237  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.41     |\n",
      "|    ep_rew_mean        | 0.887    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2418     |\n",
      "|    iterations         | 14400    |\n",
      "|    time_elapsed       | 297      |\n",
      "|    total_timesteps    | 720000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0971  |\n",
      "|    explained_variance | 0.244    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14399    |\n",
      "|    policy_loss        | -0.00132 |\n",
      "|    value_loss         | 0.00343  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 4.03      |\n",
      "|    ep_rew_mean        | 0.897     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2419      |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 725000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0847   |\n",
      "|    explained_variance | 0.218     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -0.000503 |\n",
      "|    value_loss         | 0.00569   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 11.1     |\n",
      "|    ep_rew_mean        | 0.694    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2419     |\n",
      "|    iterations         | 14600    |\n",
      "|    time_elapsed       | 301      |\n",
      "|    total_timesteps    | 730000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0272  |\n",
      "|    explained_variance | 0.0421   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14599    |\n",
      "|    policy_loss        | 0.00321  |\n",
      "|    value_loss         | 0.157    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.21      |\n",
      "|    ep_rew_mean        | 0.92      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2419      |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 735000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000721 |\n",
      "|    explained_variance | 0.77      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -7.94e-07 |\n",
      "|    value_loss         | 0.000192  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.98     |\n",
      "|    ep_rew_mean        | 0.926    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2420     |\n",
      "|    iterations         | 14800    |\n",
      "|    time_elapsed       | 305      |\n",
      "|    total_timesteps    | 740000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00108 |\n",
      "|    explained_variance | 0.73     |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14799    |\n",
      "|    policy_loss        | 1.53e-06 |\n",
      "|    value_loss         | 0.000209 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.48      |\n",
      "|    ep_rew_mean        | 0.913     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2421      |\n",
      "|    iterations         | 14900     |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 745000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000592 |\n",
      "|    explained_variance | 0.613     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14899     |\n",
      "|    policy_loss        | -1.63e-06 |\n",
      "|    value_loss         | 0.000255  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.10 +/- 0.28\n",
      "Episode length: 3.00 +/- 1.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3         |\n",
      "|    mean_reward        | 0.095     |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 750000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0578   |\n",
      "|    explained_variance | 0.553     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -0.000711 |\n",
      "|    value_loss         | 0.00037   |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.14     |\n",
      "|    ep_rew_mean     | 0.922    |\n",
      "| time/              |          |\n",
      "|    fps             | 2420     |\n",
      "|    iterations      | 15000    |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 750000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.92      |\n",
      "|    ep_rew_mean        | 0.927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2419      |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 311       |\n",
      "|    total_timesteps    | 755000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0151   |\n",
      "|    explained_variance | 0.51      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -0.000119 |\n",
      "|    value_loss         | 0.000433  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.24     |\n",
      "|    ep_rew_mean        | 0.901    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2419     |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 314      |\n",
      "|    total_timesteps    | 760000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.133   |\n",
      "|    explained_variance | 0.248    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0.00191 |\n",
      "|    value_loss         | 0.00117  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.67     |\n",
      "|    ep_rew_mean        | 0.899    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2418     |\n",
      "|    iterations         | 15300    |\n",
      "|    time_elapsed       | 316      |\n",
      "|    total_timesteps    | 765000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0685  |\n",
      "|    explained_variance | -0.293   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15299    |\n",
      "|    policy_loss        | 0.000191 |\n",
      "|    value_loss         | 0.00129  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.94      |\n",
      "|    ep_rew_mean        | 0.927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 318       |\n",
      "|    total_timesteps    | 770000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.02     |\n",
      "|    explained_variance | 0.565     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -0.000224 |\n",
      "|    value_loss         | 0.000262  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.86      |\n",
      "|    ep_rew_mean        | 0.909     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2413      |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 321       |\n",
      "|    total_timesteps    | 775000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0313   |\n",
      "|    explained_variance | 0.633     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -0.000202 |\n",
      "|    value_loss         | 0.000573  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.78      |\n",
      "|    ep_rew_mean        | 0.931     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 323       |\n",
      "|    total_timesteps    | 780000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0184   |\n",
      "|    explained_variance | 0.75      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | -0.000113 |\n",
      "|    value_loss         | 0.000218  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.1       |\n",
      "|    ep_rew_mean        | 0.923     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 785000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.014    |\n",
      "|    explained_variance | 0.68      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -7.17e-05 |\n",
      "|    value_loss         | 0.000265  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 0.925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 327       |\n",
      "|    total_timesteps    | 790000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.033    |\n",
      "|    explained_variance | 0.483     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | -0.000367 |\n",
      "|    value_loss         | 0.000459  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.9      |\n",
      "|    ep_rew_mean        | 0.928    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 15900    |\n",
      "|    time_elapsed       | 329      |\n",
      "|    total_timesteps    | 795000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00494 |\n",
      "|    explained_variance | 0.655    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15899    |\n",
      "|    policy_loss        | -2.1e-05 |\n",
      "|    value_loss         | 0.000299 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.80 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.8      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 800000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0393  |\n",
      "|    explained_variance | 0.101    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0.0067  |\n",
      "|    value_loss         | 0.0866   |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.75     |\n",
      "|    ep_rew_mean     | 0.866    |\n",
      "| time/              |          |\n",
      "|    fps             | 2415     |\n",
      "|    iterations      | 16000    |\n",
      "|    time_elapsed    | 331      |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.8      |\n",
      "|    ep_rew_mean        | 0.93     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2414     |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 805000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00111 |\n",
      "|    explained_variance | 0.782    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 3.76e-06 |\n",
      "|    value_loss         | 0.000227 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.05      |\n",
      "|    ep_rew_mean        | 0.924     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 335       |\n",
      "|    total_timesteps    | 810000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00802  |\n",
      "|    explained_variance | 0.7       |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | -1.14e-06 |\n",
      "|    value_loss         | 0.000311  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.9       |\n",
      "|    ep_rew_mean        | 0.928     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2413      |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 337       |\n",
      "|    total_timesteps    | 815000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00226  |\n",
      "|    explained_variance | 0.843     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -5.44e-06 |\n",
      "|    value_loss         | 0.000213  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.21      |\n",
      "|    ep_rew_mean        | 0.901     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2414      |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 339       |\n",
      "|    total_timesteps    | 820000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00409  |\n",
      "|    explained_variance | 0.397     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -7.21e-06 |\n",
      "|    value_loss         | 0.00478   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.24      |\n",
      "|    ep_rew_mean        | 0.919     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 341       |\n",
      "|    total_timesteps    | 825000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00997  |\n",
      "|    explained_variance | 0.495     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -2.85e-05 |\n",
      "|    value_loss         | 0.000317  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.1      |\n",
      "|    ep_rew_mean        | 0.913    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 16600    |\n",
      "|    time_elapsed       | 343      |\n",
      "|    total_timesteps    | 830000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0356  |\n",
      "|    explained_variance | 0.644    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 16599    |\n",
      "|    policy_loss        | 0.000126 |\n",
      "|    value_loss         | 0.000307 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91     |\n",
      "|    ep_rew_mean        | 0.927    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 16700    |\n",
      "|    time_elapsed       | 345      |\n",
      "|    total_timesteps    | 835000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0132  |\n",
      "|    explained_variance | 0.614    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 16699    |\n",
      "|    policy_loss        | -0.00472 |\n",
      "|    value_loss         | 0.000471 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.06      |\n",
      "|    ep_rew_mean        | 0.924     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 347       |\n",
      "|    total_timesteps    | 840000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0103   |\n",
      "|    explained_variance | 0.434     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | -5.84e-05 |\n",
      "|    value_loss         | 0.000267  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.16      |\n",
      "|    ep_rew_mean        | 0.921     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 845000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0143   |\n",
      "|    explained_variance | 0.717     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | -8.39e-05 |\n",
      "|    value_loss         | 0.000215  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.2       |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 850000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000341 |\n",
      "|    explained_variance | 0.815     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 4.2e-07   |\n",
      "|    value_loss         | 0.000157  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.79     |\n",
      "|    ep_rew_mean     | 0.93     |\n",
      "| time/              |          |\n",
      "|    fps             | 2414     |\n",
      "|    iterations      | 17000    |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 850000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 0.925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2413      |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 354       |\n",
      "|    total_timesteps    | 855000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0139   |\n",
      "|    explained_variance | 0.703     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | -0.000127 |\n",
      "|    value_loss         | 0.000284  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.03     |\n",
      "|    ep_rew_mean        | 0.915    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2413     |\n",
      "|    iterations         | 17200    |\n",
      "|    time_elapsed       | 356      |\n",
      "|    total_timesteps    | 860000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0397  |\n",
      "|    explained_variance | 0.214    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17199    |\n",
      "|    policy_loss        | -0.00829 |\n",
      "|    value_loss         | 0.00122  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.7      |\n",
      "|    ep_rew_mean        | 0.797    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2414     |\n",
      "|    iterations         | 17300    |\n",
      "|    time_elapsed       | 358      |\n",
      "|    total_timesteps    | 865000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00405 |\n",
      "|    explained_variance | -0.00162 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17299    |\n",
      "|    policy_loss        | -0.00572 |\n",
      "|    value_loss         | 0.0482   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.19     |\n",
      "|    ep_rew_mean        | 0.874    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2415     |\n",
      "|    iterations         | 17400    |\n",
      "|    time_elapsed       | 360      |\n",
      "|    total_timesteps    | 870000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0826  |\n",
      "|    explained_variance | -0.103   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17399    |\n",
      "|    policy_loss        | -0.00537 |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.95      |\n",
      "|    ep_rew_mean        | 0.926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 362       |\n",
      "|    total_timesteps    | 875000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0143   |\n",
      "|    explained_variance | 0.575     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -9.57e-05 |\n",
      "|    value_loss         | 0.000376  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.98      |\n",
      "|    ep_rew_mean        | 0.926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 364       |\n",
      "|    total_timesteps    | 880000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0621   |\n",
      "|    explained_variance | 0.449     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -0.000602 |\n",
      "|    value_loss         | 0.000403  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.14      |\n",
      "|    ep_rew_mean        | 0.922     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 366       |\n",
      "|    total_timesteps    | 885000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0112   |\n",
      "|    explained_variance | 0.602     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | -4.93e-05 |\n",
      "|    value_loss         | 0.000324  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 0.925     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 890000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0104   |\n",
      "|    explained_variance | 0.675     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -4.92e-05 |\n",
      "|    value_loss         | 0.000214  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.2       |\n",
      "|    ep_rew_mean        | 0.92      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 370       |\n",
      "|    total_timesteps    | 895000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00382  |\n",
      "|    explained_variance | 0.677     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | -1.69e-05 |\n",
      "|    value_loss         | 0.000261  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 3.2      |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 900000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00739 |\n",
      "|    explained_variance | 0.808    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -5.1e-05 |\n",
      "|    value_loss         | 0.000156 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.88     |\n",
      "|    ep_rew_mean     | 0.928    |\n",
      "| time/              |          |\n",
      "|    fps             | 2416     |\n",
      "|    iterations      | 18000    |\n",
      "|    time_elapsed    | 372      |\n",
      "|    total_timesteps | 900000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.1       |\n",
      "|    ep_rew_mean        | 0.913     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2416      |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 374       |\n",
      "|    total_timesteps    | 905000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0283   |\n",
      "|    explained_variance | 0.285     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -0.000109 |\n",
      "|    value_loss         | 0.00106   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.97      |\n",
      "|    ep_rew_mean        | 0.926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 376       |\n",
      "|    total_timesteps    | 910000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00521  |\n",
      "|    explained_variance | 0.738     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | -4.15e-05 |\n",
      "|    value_loss         | 0.00024   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.9       |\n",
      "|    ep_rew_mean        | 0.928     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 378       |\n",
      "|    total_timesteps    | 915000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0172   |\n",
      "|    explained_variance | 0.592     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | -9.88e-05 |\n",
      "|    value_loss         | 0.000254  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.94      |\n",
      "|    ep_rew_mean        | 0.927     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 380       |\n",
      "|    total_timesteps    | 920000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.31e-05 |\n",
      "|    explained_variance | 0.804     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -2.92e-08 |\n",
      "|    value_loss         | 0.000122  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.11      |\n",
      "|    ep_rew_mean        | 0.922     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2415      |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 382       |\n",
      "|    total_timesteps    | 925000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0266   |\n",
      "|    explained_variance | 0.696     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -0.000205 |\n",
      "|    value_loss         | 0.00039   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.08     |\n",
      "|    ep_rew_mean        | 0.923    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2412     |\n",
      "|    iterations         | 18600    |\n",
      "|    time_elapsed       | 385      |\n",
      "|    total_timesteps    | 930000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0126  |\n",
      "|    explained_variance | 0.427    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 18599    |\n",
      "|    policy_loss        | -9.8e-05 |\n",
      "|    value_loss         | 0.000403 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.86      |\n",
      "|    ep_rew_mean        | 0.929     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2410      |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 387       |\n",
      "|    total_timesteps    | 935000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.029    |\n",
      "|    explained_variance | 0.574     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -0.000228 |\n",
      "|    value_loss         | 0.000487  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.91     |\n",
      "|    ep_rew_mean        | 0.918    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2409     |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 390      |\n",
      "|    total_timesteps    | 940000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0275  |\n",
      "|    explained_variance | 0.587    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -0.0119  |\n",
      "|    value_loss         | 0.000532 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.08      |\n",
      "|    ep_rew_mean        | 0.914     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2409      |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 392       |\n",
      "|    total_timesteps    | 945000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000993 |\n",
      "|    explained_variance | 0.734     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -5.9e-06  |\n",
      "|    value_loss         | 0.000547  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.00 +/- 1.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3         |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 950000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00535  |\n",
      "|    explained_variance | 0.7       |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -2.96e-05 |\n",
      "|    value_loss         | 0.000184  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.44     |\n",
      "|    ep_rew_mean     | 0.901    |\n",
      "| time/              |          |\n",
      "|    fps             | 2409     |\n",
      "|    iterations      | 19000    |\n",
      "|    time_elapsed    | 394      |\n",
      "|    total_timesteps | 950000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.41      |\n",
      "|    ep_rew_mean        | 0.843     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2409      |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 396       |\n",
      "|    total_timesteps    | 955000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0273   |\n",
      "|    explained_variance | 0.013     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -0.000293 |\n",
      "|    value_loss         | 0.151     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.23     |\n",
      "|    ep_rew_mean        | 0.919    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2409     |\n",
      "|    iterations         | 19200    |\n",
      "|    time_elapsed       | 398      |\n",
      "|    total_timesteps    | 960000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0215  |\n",
      "|    explained_variance | 0.707    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19199    |\n",
      "|    policy_loss        | 2.83e-05 |\n",
      "|    value_loss         | 0.000267 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.81     |\n",
      "|    ep_rew_mean        | 0.844    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2409     |\n",
      "|    iterations         | 19300    |\n",
      "|    time_elapsed       | 400      |\n",
      "|    total_timesteps    | 965000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.207   |\n",
      "|    explained_variance | 0.307    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19299    |\n",
      "|    policy_loss        | -0.00586 |\n",
      "|    value_loss         | 0.00333  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.04     |\n",
      "|    ep_rew_mean        | 0.924    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2409     |\n",
      "|    iterations         | 19400    |\n",
      "|    time_elapsed       | 402      |\n",
      "|    total_timesteps    | 970000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00346 |\n",
      "|    explained_variance | 0.766    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19399    |\n",
      "|    policy_loss        | 1.39e-05 |\n",
      "|    value_loss         | 0.000185 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.97      |\n",
      "|    ep_rew_mean        | 0.926     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2409      |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 404       |\n",
      "|    total_timesteps    | 975000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0418   |\n",
      "|    explained_variance | 0.654     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -0.000421 |\n",
      "|    value_loss         | 0.000298  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 0.925    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2409     |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 406      |\n",
      "|    total_timesteps    | 980000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0947  |\n",
      "|    explained_variance | 0.449    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0.00389 |\n",
      "|    value_loss         | 0.000614 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.88      |\n",
      "|    ep_rew_mean        | 0.919     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2408      |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 408       |\n",
      "|    total_timesteps    | 985000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00259  |\n",
      "|    explained_variance | 0.667     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | -3.64e-06 |\n",
      "|    value_loss         | 0.00045   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.52      |\n",
      "|    ep_rew_mean        | 0.912     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2408      |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 411       |\n",
      "|    total_timesteps    | 990000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0174   |\n",
      "|    explained_variance | 0.227     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -9.21e-05 |\n",
      "|    value_loss         | 0.000252  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.99     |\n",
      "|    ep_rew_mean        | 0.812    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2408     |\n",
      "|    iterations         | 19900    |\n",
      "|    time_elapsed       | 413      |\n",
      "|    total_timesteps    | 995000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.1     |\n",
      "|    explained_variance | 0.031    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19899    |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 3.20 +/- 0.98\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 3.2       |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 1000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.2e-06  |\n",
      "|    explained_variance | 0.933     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -3.81e-09 |\n",
      "|    value_loss         | 6.44e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.01     |\n",
      "|    ep_rew_mean     | 0.925    |\n",
      "| time/              |          |\n",
      "|    fps             | 2409     |\n",
      "|    iterations      | 20000    |\n",
      "|    time_elapsed    | 415      |\n",
      "|    total_timesteps | 1000000  |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 14.2     |\n",
      "|    ep_rew_mean     | 0.315    |\n",
      "| time/              |          |\n",
      "|    fps             | 3318     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 14.2        |\n",
      "|    ep_rew_mean          | 0.401       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1480        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016247842 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -8.34e-06   |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00811     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.0488      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015309034 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.0903      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -2.38e-05   |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 0.0598      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.2     |\n",
      "|    ep_rew_mean     | 0.517    |\n",
      "| time/              |          |\n",
      "|    fps             | 1264     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.1         |\n",
      "|    ep_rew_mean          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1186        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017479967 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.106       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.00774    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 0.061       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 12.20 +/- 15.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.2       |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 100000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02017976 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.76      |\n",
      "|    explained_variance   | 0.173      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0222     |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.0281    |\n",
      "|    value_loss           | 0.0627     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 8.44     |\n",
      "|    ep_rew_mean     | 0.722    |\n",
      "| time/              |          |\n",
      "|    fps             | 1115     |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 102400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.96        |\n",
      "|    ep_rew_mean          | 0.787       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1095        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022631254 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0384     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.0571      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.57        |\n",
      "|    ep_rew_mean          | 0.852       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030757207 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00624     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036828183 |\n",
      "|    clip_fraction        | 0.455       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00401     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 0.0374      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.74     |\n",
      "|    ep_rew_mean     | 0.906    |\n",
      "| time/              |          |\n",
      "|    fps             | 1071     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 152      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.88        |\n",
      "|    ep_rew_mean          | 0.873       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1062        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048651792 |\n",
      "|    clip_fraction        | 0.45        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 0.033       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 200000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05047518 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.839     |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.00422   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    value_loss           | 0.0186     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.89     |\n",
      "|    ep_rew_mean     | 0.909    |\n",
      "| time/              |          |\n",
      "|    fps             | 1055     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.22        |\n",
      "|    ep_rew_mean          | 0.945       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1041        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052492082 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.571      |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.0108      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.19       |\n",
      "|    ep_rew_mean          | 0.927      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1035       |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 237        |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05695436 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.274     |\n",
      "|    explained_variance   | 0.0537     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0479    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.00902    |\n",
      "|    value_loss           | 0.00681    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 250000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05070268 |\n",
      "|    clip_fraction        | 0.0941     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.161     |\n",
      "|    explained_variance   | 0.031      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0103    |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | 0.0115     |\n",
      "|    value_loss           | 0.00864    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.06     |\n",
      "|    ep_rew_mean     | 0.948    |\n",
      "| time/              |          |\n",
      "|    fps             | 1029     |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 258      |\n",
      "|    total_timesteps | 266240   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 7.56      |\n",
      "|    ep_rew_mean          | 0.801     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1028      |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 278       |\n",
      "|    total_timesteps      | 286720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3545983 |\n",
      "|    clip_fraction        | 0.22      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.148    |\n",
      "|    explained_variance   | 0.0287    |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.047    |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | 0.00977   |\n",
      "|    value_loss           | 0.00344   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 12.20 +/- 15.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 12.2        |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037166394 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 0.0365      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.21     |\n",
      "|    ep_rew_mean     | 0.81     |\n",
      "| time/              |          |\n",
      "|    fps             | 1028     |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 298      |\n",
      "|    total_timesteps | 307200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 7.06        |\n",
      "|    ep_rew_mean          | 0.819       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1028        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071493775 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00175     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 0.0265      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.59       |\n",
      "|    ep_rew_mean          | 0.718      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1028       |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 338        |\n",
      "|    total_timesteps      | 348160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04655019 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.706     |\n",
      "|    explained_variance   | 0.694      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.00273    |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 0.0302     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 25.80 +/- 15.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25.8       |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 350000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.33275193 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | 0.447      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0184     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00986   |\n",
      "|    value_loss           | 0.0512     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 16.4     |\n",
      "|    ep_rew_mean     | 0.555    |\n",
      "| time/              |          |\n",
      "|    fps             | 1028     |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 358      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 12        |\n",
      "|    ep_rew_mean          | 0.686     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1028      |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 378       |\n",
      "|    total_timesteps      | 389120    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.6400433 |\n",
      "|    clip_fraction        | 0.41      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.532    |\n",
      "|    explained_variance   | -1.06     |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0401   |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | 1.06      |\n",
      "|    value_loss           | 0.0444    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 19.00 +/- 17.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 19         |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 400000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15073793 |\n",
      "|    clip_fraction        | 0.436      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.804     |\n",
      "|    explained_variance   | 0.329      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.016     |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00482   |\n",
      "|    value_loss           | 0.0318     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.4     |\n",
      "|    ep_rew_mean     | 0.673    |\n",
      "| time/              |          |\n",
      "|    fps             | 1015     |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 403      |\n",
      "|    total_timesteps | 409600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.63       |\n",
      "|    ep_rew_mean          | 0.772      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1015       |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 430080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04423834 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.872     |\n",
      "|    explained_variance   | 0.466      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0424     |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.000773  |\n",
      "|    value_loss           | 0.0367     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 19.00 +/- 17.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 19        |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 450000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1947163 |\n",
      "|    clip_fraction        | 0.528     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.918    |\n",
      "|    explained_variance   | 0.709     |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0697   |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | 0.0049    |\n",
      "|    value_loss           | 0.0178    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.74     |\n",
      "|    ep_rew_mean     | 0.867    |\n",
      "| time/              |          |\n",
      "|    fps             | 1015     |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 443      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.16        |\n",
      "|    ep_rew_mean          | 0.895       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1014        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045438014 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0075     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0329      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.14        |\n",
      "|    ep_rew_mean          | 0.921       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1014        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035019413 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.627      |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0176     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 5.40 +/- 10.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5.4        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 500000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04177625 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.517     |\n",
      "|    explained_variance   | 0.432      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.037     |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00763   |\n",
      "|    value_loss           | 0.0123     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.96     |\n",
      "|    ep_rew_mean     | 0.926    |\n",
      "| time/              |          |\n",
      "|    fps             | 1013     |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 505      |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.91        |\n",
      "|    ep_rew_mean          | 0.927       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1011        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020963794 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0015      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0073      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 5.40 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5.4         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058761753 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.363      |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0079     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.00578     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.95     |\n",
      "|    ep_rew_mean     | 0.926    |\n",
      "| time/              |          |\n",
      "|    fps             | 1010     |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 547      |\n",
      "|    total_timesteps | 552960   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.08       |\n",
      "|    ep_rew_mean          | 0.948      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1006       |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 569        |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08416744 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.33      |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0146    |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0033    |\n",
      "|    value_loss           | 0.00819    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.15       |\n",
      "|    ep_rew_mean          | 0.788      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1006       |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 590        |\n",
      "|    total_timesteps      | 593920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22017531 |\n",
      "|    clip_fraction        | 0.311      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.361     |\n",
      "|    explained_variance   | -0.27      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.027     |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | 0.0145     |\n",
      "|    value_loss           | 0.00209    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 25.80 +/- 15.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 25.8       |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 600000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07225896 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.438     |\n",
      "|    explained_variance   | -0.0159    |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0129    |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.00602   |\n",
      "|    value_loss           | 0.0265     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 7.12     |\n",
      "|    ep_rew_mean     | 0.81     |\n",
      "| time/              |          |\n",
      "|    fps             | 1006     |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 610      |\n",
      "|    total_timesteps | 614400   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.08       |\n",
      "|    ep_rew_mean          | 0.871      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1007       |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 630        |\n",
      "|    total_timesteps      | 634880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09417714 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.599     |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0355    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | 0.00749    |\n",
      "|    value_loss           | 0.0233     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 8.80 +/- 13.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.8         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053010352 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0181     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 0.0344      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.47     |\n",
      "|    ep_rew_mean     | 0.913    |\n",
      "| time/              |          |\n",
      "|    fps             | 1006     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 650      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.47        |\n",
      "|    ep_rew_mean          | 0.913       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1006        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 671         |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031860597 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0228      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.82       |\n",
      "|    ep_rew_mean          | 0.905      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1004       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 693        |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14915122 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.577     |\n",
      "|    explained_variance   | 0.175      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0693    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0055    |\n",
      "|    value_loss           | 0.0107     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 5.40 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5.4         |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055634595 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.543      |\n",
      "|    explained_variance   | -0.373      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0782     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.89     |\n",
      "|    ep_rew_mean     | 0.928    |\n",
      "| time/              |          |\n",
      "|    fps             | 1006     |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 712      |\n",
      "|    total_timesteps | 716800   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.38       |\n",
      "|    ep_rew_mean          | 0.916      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1010       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 729        |\n",
      "|    total_timesteps      | 737280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16962932 |\n",
      "|    clip_fraction        | 0.515      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.533     |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0759    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | 0.0112     |\n",
      "|    value_loss           | 0.00409    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 8.80 +/- 13.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 8.8        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 750000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20040941 |\n",
      "|    clip_fraction        | 0.554      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.501     |\n",
      "|    explained_variance   | -0.158     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0981    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | 0.0435     |\n",
      "|    value_loss           | 0.00937    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.98     |\n",
      "|    ep_rew_mean     | 0.844    |\n",
      "| time/              |          |\n",
      "|    fps             | 1013     |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 747      |\n",
      "|    total_timesteps | 757760   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.68       |\n",
      "|    ep_rew_mean          | 0.852      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1017       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 765        |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07445959 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.426     |\n",
      "|    explained_variance   | 0.35       |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0358    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    value_loss           | 0.0227     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.38       |\n",
      "|    ep_rew_mean          | 0.924      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1019       |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 783        |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14811382 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.373     |\n",
      "|    explained_variance   | 0.842      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0674    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0605    |\n",
      "|    value_loss           | 0.00988    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 19.00 +/- 17.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 19         |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 800000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17661957 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.335     |\n",
      "|    explained_variance   | -0.0466    |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0199    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0243    |\n",
      "|    value_loss           | 0.0184     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.95     |\n",
      "|    ep_rew_mean     | 0.901    |\n",
      "| time/              |          |\n",
      "|    fps             | 1023     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 800      |\n",
      "|    total_timesteps | 819200   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.31       |\n",
      "|    ep_rew_mean          | 0.873      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1026       |\n",
      "|    iterations           | 41         |\n",
      "|    time_elapsed         | 817        |\n",
      "|    total_timesteps      | 839680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06262901 |\n",
      "|    clip_fraction        | 0.472      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.579     |\n",
      "|    explained_variance   | -0.225     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0555    |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | -0.0464    |\n",
      "|    value_loss           | 0.0159     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 8.80 +/- 13.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 8.8        |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 850000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07037509 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0243    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0317    |\n",
      "|    value_loss           | 0.018      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51     |\n",
      "|    ep_rew_mean     | 0.937    |\n",
      "| time/              |          |\n",
      "|    fps             | 1029     |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 835      |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.71       |\n",
      "|    ep_rew_mean          | 0.932      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1032       |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 852        |\n",
      "|    total_timesteps      | 880640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04611683 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.566     |\n",
      "|    explained_variance   | -0.295     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0502    |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.00562    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 900000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04020935 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.519     |\n",
      "|    explained_variance   | 0.0516     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0135     |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0104     |\n",
      "|    value_loss           | 0.00361    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.18     |\n",
      "|    ep_rew_mean     | 0.914    |\n",
      "| time/              |          |\n",
      "|    fps             | 1035     |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 870      |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.47       |\n",
      "|    ep_rew_mean          | 0.938      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1037       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 888        |\n",
      "|    total_timesteps      | 921600     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03592015 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.477     |\n",
      "|    explained_variance   | 0.171      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0362    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 0.00917    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17        |\n",
      "|    ep_rew_mean          | 0.946       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1039        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 906         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029953232 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.281      |\n",
      "|    explained_variance   | -0.392      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.00212     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 15.60 +/- 16.66\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 15.6      |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 950000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7561901 |\n",
      "|    clip_fraction        | 0.347     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.137    |\n",
      "|    explained_variance   | -0.192    |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0875   |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -0.0573   |\n",
      "|    value_loss           | 0.000623  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.3     |\n",
      "|    ep_rew_mean     | 0.666    |\n",
      "| time/              |          |\n",
      "|    fps             | 1042     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 923      |\n",
      "|    total_timesteps | 962560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.72       |\n",
      "|    ep_rew_mean          | 0.907      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1045       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 940        |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13319804 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.916     |\n",
      "|    explained_variance   | -0.0232    |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0493    |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | 0.00282    |\n",
      "|    value_loss           | 0.0357     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 36        |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1000000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5297935 |\n",
      "|    clip_fraction        | 0.454     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.74     |\n",
      "|    explained_variance   | -0.0376   |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0565   |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | 0.044     |\n",
      "|    value_loss           | 0.0128    |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.2     |\n",
      "|    ep_rew_mean     | 0.476    |\n",
      "| time/              |          |\n",
      "|    fps             | 1048     |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 957      |\n",
      "|    total_timesteps | 1003520  |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.57     |\n",
      "|    ep_rew_mean        | 0.554    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1956     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.56    |\n",
      "|    explained_variance | -0.102   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0114  |\n",
      "|    value_loss         | 0.0658   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.16     |\n",
      "|    ep_rew_mean        | 0.478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1988     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.659   |\n",
      "|    explained_variance | -0.0713  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.0773  |\n",
      "|    value_loss         | 0.0397   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.35     |\n",
      "|    ep_rew_mean        | 0.406    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2281     |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.648   |\n",
      "|    explained_variance | 0.0157   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0172  |\n",
      "|    value_loss         | 0.0583   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.5      |\n",
      "|    ep_rew_mean        | 0.509    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2453     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.678   |\n",
      "|    explained_variance | -0.00856 |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0403   |\n",
      "|    value_loss         | 0.0886   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 6.87     |\n",
      "|    ep_rew_mean        | 0.505    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2559     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 25000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.491   |\n",
      "|    explained_variance | -0.0125  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0119  |\n",
      "|    value_loss         | 0.0393   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.49     |\n",
      "|    ep_rew_mean        | 0.346    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2631     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.826   |\n",
      "|    explained_variance | -0.0089  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.00287  |\n",
      "|    value_loss         | 0.0869   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 4.95     |\n",
      "|    ep_rew_mean        | 0.358    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2686     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 35000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.01    |\n",
      "|    explained_variance | -0.0286  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.0305  |\n",
      "|    value_loss         | 0.096    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 13.3     |\n",
      "|    ep_rew_mean        | 0.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2733     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.312   |\n",
      "|    explained_variance | 0.0233   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.0609   |\n",
      "|    value_loss         | 0.0481   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.47     |\n",
      "|    ep_rew_mean        | 0.557    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2765     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 45000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.559   |\n",
      "|    explained_variance | 0.0457   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.0173  |\n",
      "|    value_loss         | 0.0883   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2        |\n",
      "|    mean_reward        | 0.38     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.443   |\n",
      "|    explained_variance | 0.0653   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.0373  |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.22     |\n",
      "|    ep_rew_mean     | 0.39     |\n",
      "| time/              |          |\n",
      "|    fps             | 2781     |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 50000    |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.78     |\n",
      "|    ep_rew_mean        | 0.429    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2783     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 55000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.339   |\n",
      "|    explained_variance | 0.00234  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0122  |\n",
      "|    value_loss         | 0.184    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.31      |\n",
      "|    ep_rew_mean        | 0.379     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2765      |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.338    |\n",
      "|    explained_variance | -0.000461 |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 0.0305    |\n",
      "|    value_loss         | 0.19      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.46     |\n",
      "|    ep_rew_mean        | 0.374    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2758     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 65000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.606   |\n",
      "|    explained_variance | 0.086    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.0199  |\n",
      "|    value_loss         | 0.154    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.13     |\n",
      "|    ep_rew_mean        | 0.587    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2752     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.292   |\n",
      "|    explained_variance | -0.0308  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0279   |\n",
      "|    value_loss         | 0.164    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.11     |\n",
      "|    ep_rew_mean        | 0.464    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2741     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 75000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.186   |\n",
      "|    explained_variance | 0.0889   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.0407  |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.52     |\n",
      "|    ep_rew_mean        | 0.51     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2735     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.334   |\n",
      "|    explained_variance | 0.252    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | -0.0374  |\n",
      "|    value_loss         | 0.144    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.12     |\n",
      "|    ep_rew_mean        | 0.425    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2724     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 85000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.168   |\n",
      "|    explained_variance | 0.0303   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.00389 |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.05     |\n",
      "|    ep_rew_mean        | 0.512    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2727     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 32       |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.146   |\n",
      "|    explained_variance | 0.124    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.0038   |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 7.24     |\n",
      "|    ep_rew_mean        | 0.457    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2734     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 95000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.147   |\n",
      "|    explained_variance | 0.506    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.0177   |\n",
      "|    value_loss         | 0.0151   |\n",
      "------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.47 +/- 0.48\n",
      "Episode length: 2.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2        |\n",
      "|    mean_reward        | 0.475    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.115   |\n",
      "|    explained_variance | 0.114    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.00229 |\n",
      "|    value_loss         | 0.183    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.05     |\n",
      "|    ep_rew_mean     | 0.484    |\n",
      "| time/              |          |\n",
      "|    fps             | 2734     |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 100000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.35     |\n",
      "|    ep_rew_mean        | 0.427    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2726     |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 105000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.23    |\n",
      "|    explained_variance | 0.111    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0372  |\n",
      "|    value_loss         | 0.174    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.4      |\n",
      "|    ep_rew_mean        | 0.385    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2729     |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 110000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.411   |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.0148   |\n",
      "|    value_loss         | 0.0864   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.85     |\n",
      "|    ep_rew_mean        | 0.448    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2737     |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 115000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.234   |\n",
      "|    explained_variance | 0.0656   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.00829 |\n",
      "|    value_loss         | 0.128    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.09      |\n",
      "|    ep_rew_mean        | 0.474     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2740      |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 120000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0963   |\n",
      "|    explained_variance | 0.0457    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -0.000551 |\n",
      "|    value_loss         | 0.197     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3      |\n",
      "|    ep_rew_mean        | 0.405    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2736     |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 125000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.17    |\n",
      "|    explained_variance | 0.0556   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.0159  |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.2     |\n",
      "|    ep_rew_mean        | 0.383    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2730     |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 130000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.129   |\n",
      "|    explained_variance | 0.165    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.0548   |\n",
      "|    value_loss         | 0.0478   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.36     |\n",
      "|    ep_rew_mean        | 0.544    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2729     |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 135000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.182   |\n",
      "|    explained_variance | 0.0021   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | -0.032   |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.22     |\n",
      "|    ep_rew_mean        | 0.463    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2731     |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 140000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.109   |\n",
      "|    explained_variance | 0.00534  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -0.0237  |\n",
      "|    value_loss         | 0.167    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.13     |\n",
      "|    ep_rew_mean        | 0.587    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2732     |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 145000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.149   |\n",
      "|    explained_variance | -0.046   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.00516 |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.47 +/- 0.47\n",
      "Episode length: 2.40 +/- 0.80\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.4      |\n",
      "|    mean_reward        | 0.47     |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 150000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.135   |\n",
      "|    explained_variance | -0.084   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 0.0395   |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21     |\n",
      "|    ep_rew_mean     | 0.414    |\n",
      "| time/              |          |\n",
      "|    fps             | 2736     |\n",
      "|    iterations      | 3000     |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 150000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 5.87     |\n",
      "|    ep_rew_mean        | 0.487    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2740     |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 155000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0865  |\n",
      "|    explained_variance | 0.247    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | 0.00588  |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.68     |\n",
      "|    ep_rew_mean        | 0.487    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2737     |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 160000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.15    |\n",
      "|    explained_variance | -0.026   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.00427  |\n",
      "|    value_loss         | 0.106    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.58     |\n",
      "|    ep_rew_mean        | 0.567    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2743     |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 165000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.189   |\n",
      "|    explained_variance | 0.017    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0432   |\n",
      "|    value_loss         | 0.11     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.41     |\n",
      "|    ep_rew_mean        | 0.476    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2750     |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 170000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0718  |\n",
      "|    explained_variance | -0.0246  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.00567 |\n",
      "|    value_loss         | 0.215    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 10.9     |\n",
      "|    ep_rew_mean        | 0.352    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2761     |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 175000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.197   |\n",
      "|    explained_variance | -0.0423  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0335  |\n",
      "|    value_loss         | 0.118    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.4      |\n",
      "|    ep_rew_mean        | 0.487    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2762     |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 180000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.036   |\n",
      "|    explained_variance | -0.0532  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.00157  |\n",
      "|    value_loss         | 0.238    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.25     |\n",
      "|    ep_rew_mean        | 0.49     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2769     |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 185000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0659  |\n",
      "|    explained_variance | -0.03    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.00375  |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.47     |\n",
      "|    ep_rew_mean        | 0.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 2767     |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 190000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0444  |\n",
      "|    explained_variance | 0.0105   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.00162  |\n",
      "|    value_loss         | 0.149    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.64     |\n",
      "|    ep_rew_mean        | 0.632    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2774     |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 195000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.137   |\n",
      "|    explained_variance | 0.0347   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.0255  |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.47 +/- 0.48\n",
      "Episode length: 2.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2        |\n",
      "|    mean_reward        | 0.475    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 200000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0269  |\n",
      "|    explained_variance | 0.0492   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.00857 |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.06     |\n",
      "|    ep_rew_mean     | 0.541    |\n",
      "| time/              |          |\n",
      "|    fps             | 2777     |\n",
      "|    iterations      | 4000     |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 200000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.13     |\n",
      "|    ep_rew_mean        | 0.444    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2770     |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 205000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0761  |\n",
      "|    explained_variance | 0.00282  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.0202   |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.18     |\n",
      "|    ep_rew_mean        | 0.566    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2764     |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 210000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0231  |\n",
      "|    explained_variance | 0.049    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.00166  |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.28     |\n",
      "|    ep_rew_mean        | 0.478    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2761     |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 77       |\n",
      "|    total_timesteps    | 215000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0623  |\n",
      "|    explained_variance | -0.033   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.0267  |\n",
      "|    value_loss         | 0.197    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.14     |\n",
      "|    ep_rew_mean        | 0.595    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2758     |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 220000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0136  |\n",
      "|    explained_variance | 0.0552   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.000809 |\n",
      "|    value_loss         | 0.169    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.14     |\n",
      "|    ep_rew_mean        | 0.511    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2751     |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 225000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0659  |\n",
      "|    explained_variance | 0.102    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 0.0108   |\n",
      "|    value_loss         | 0.17     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.2      |\n",
      "|    ep_rew_mean        | 0.508    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2749     |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 230000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0139  |\n",
      "|    explained_variance | 0.149    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.000638 |\n",
      "|    value_loss         | 0.172    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.2      |\n",
      "|    ep_rew_mean        | 0.49     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2746     |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 235000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0492  |\n",
      "|    explained_variance | 0.0244   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.00611 |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.3      |\n",
      "|    ep_rew_mean        | 0.591    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2744     |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 240000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00551 |\n",
      "|    explained_variance | 0.0482   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | 0.000296 |\n",
      "|    value_loss         | 0.162    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 12.8      |\n",
      "|    ep_rew_mean        | 0.378     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2751      |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 245000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00261  |\n",
      "|    explained_variance | 0.46      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -1.61e-06 |\n",
      "|    value_loss         | 0.064     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.66 +/- 0.43\n",
      "Episode length: 2.80 +/- 0.98\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 2.8      |\n",
      "|    mean_reward        | 0.655    |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 250000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0118  |\n",
      "|    explained_variance | 0.0105   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.000174 |\n",
      "|    value_loss         | 0.163    |\n",
      "------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.22     |\n",
      "|    ep_rew_mean     | 0.453    |\n",
      "| time/              |          |\n",
      "|    fps             | 2758     |\n",
      "|    iterations      | 5000     |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 250000   |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.26     |\n",
      "|    ep_rew_mean        | 0.564    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2759     |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 255000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0111  |\n",
      "|    explained_variance | 0.0665   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 0.0203   |\n",
      "|    value_loss         | 0.191    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.24     |\n",
      "|    ep_rew_mean        | 0.669    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2757     |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 94       |\n",
      "|    total_timesteps    | 260000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00627 |\n",
      "|    explained_variance | 0.0916   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 0.000206 |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.16     |\n",
      "|    ep_rew_mean        | 0.632    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2755     |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 96       |\n",
      "|    total_timesteps    | 265000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00373 |\n",
      "|    explained_variance | 0.0114   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 5.19e-05 |\n",
      "|    value_loss         | 0.164    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.08      |\n",
      "|    ep_rew_mean        | 0.482     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2751      |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 270000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000709 |\n",
      "|    explained_variance | -0.0209   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 3.85e-05  |\n",
      "|    value_loss         | 0.206     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 11.8      |\n",
      "|    ep_rew_mean        | 0.444     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2752      |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 275000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0146   |\n",
      "|    explained_variance | 0.208     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | -0.000152 |\n",
      "|    value_loss         | 0.0257    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.38      |\n",
      "|    ep_rew_mean        | 0.694     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2757      |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 280000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000819 |\n",
      "|    explained_variance | 0.043     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 1.71e-05  |\n",
      "|    value_loss         | 0.146     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.2       |\n",
      "|    ep_rew_mean        | 0.536     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2754      |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 285000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000682 |\n",
      "|    explained_variance | 0.0397    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 2.99e-05  |\n",
      "|    value_loss         | 0.191     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.12     |\n",
      "|    ep_rew_mean        | 0.539    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2752     |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 105      |\n",
      "|    total_timesteps    | 290000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00155 |\n",
      "|    explained_variance | 0.112    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 6.18e-05 |\n",
      "|    value_loss         | 0.174    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 13.1      |\n",
      "|    ep_rew_mean        | 0.226     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2752      |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 295000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00458  |\n",
      "|    explained_variance | -0.211    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | -7.43e-05 |\n",
      "|    value_loss         | 0.000694  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 19.00 +/- 17.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 19        |\n",
      "|    mean_reward        | 0.38      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 300000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000386 |\n",
      "|    explained_variance | -0.49     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | -1.33e-06 |\n",
      "|    value_loss         | 0.00328   |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.6     |\n",
      "|    ep_rew_mean     | 0.246    |\n",
      "| time/              |          |\n",
      "|    fps             | 2758     |\n",
      "|    iterations      | 6000     |\n",
      "|    time_elapsed    | 108      |\n",
      "|    total_timesteps | 300000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.1       |\n",
      "|    ep_rew_mean        | 0.52      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2760      |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 305000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.39e-05 |\n",
      "|    explained_variance | 0.0436    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 2.37e-06  |\n",
      "|    value_loss         | 0.183     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.16      |\n",
      "|    ep_rew_mean        | 0.395     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2758      |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 310000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000958 |\n",
      "|    explained_variance | 0.0518    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 5.18e-05  |\n",
      "|    value_loss         | 0.185     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.48      |\n",
      "|    ep_rew_mean        | 0.57      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2756      |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 315000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000501 |\n",
      "|    explained_variance | -0.0231   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -1.27e-05 |\n",
      "|    value_loss         | 0.113     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.456     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2755      |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000179 |\n",
      "|    explained_variance | -0.017    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -8.95e-06 |\n",
      "|    value_loss         | 0.212     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 19.9      |\n",
      "|    ep_rew_mean        | 0.266     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2760      |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 325000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00186  |\n",
      "|    explained_variance | -0.0518   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -3.13e-06 |\n",
      "|    value_loss         | 0.0041    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.32     |\n",
      "|    ep_rew_mean        | 0.714    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2766     |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 119      |\n",
      "|    total_timesteps    | 330000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0011  |\n",
      "|    explained_variance | -0.0379  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 2.82e-05 |\n",
      "|    value_loss         | 0.123    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.16      |\n",
      "|    ep_rew_mean        | 0.633     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2764      |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 335000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000485 |\n",
      "|    explained_variance | 0.0928    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 1.03e-05  |\n",
      "|    value_loss         | 0.131     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.34      |\n",
      "|    ep_rew_mean        | 0.495     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2762      |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 340000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000576 |\n",
      "|    explained_variance | 0.121     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 1.82e-05  |\n",
      "|    value_loss         | 0.178     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.16      |\n",
      "|    ep_rew_mean        | 0.604     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2760      |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 345000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000484 |\n",
      "|    explained_variance | 0.134     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 1.3e-05   |\n",
      "|    value_loss         | 0.152     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.67 +/- 0.44\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2         |\n",
      "|    mean_reward        | 0.665     |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 350000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000229 |\n",
      "|    explained_variance | -0.00241  |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 8.53e-06  |\n",
      "|    value_loss         | 0.171     |\n",
      "-------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2        |\n",
      "|    ep_rew_mean     | 0.637    |\n",
      "| time/              |          |\n",
      "|    fps             | 2757     |\n",
      "|    iterations      | 7000     |\n",
      "|    time_elapsed    | 126      |\n",
      "|    total_timesteps | 350000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.22      |\n",
      "|    ep_rew_mean        | 0.64      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2755      |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 355000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000278 |\n",
      "|    explained_variance | -0.0204   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 5.39e-06  |\n",
      "|    value_loss         | 0.119     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 19.1     |\n",
      "|    ep_rew_mean        | 0.219    |\n",
      "| time/                 |          |\n",
      "|    fps                | 2756     |\n",
      "|    iterations         | 7200     |\n",
      "|    time_elapsed       | 130      |\n",
      "|    total_timesteps    | 360000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0409  |\n",
      "|    explained_variance | -1.48    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 7199     |\n",
      "|    policy_loss        | -0.00316 |\n",
      "|    value_loss         | 0.00233  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 20        |\n",
      "|    ep_rew_mean        | 0.19      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2764      |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 365000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.04e-05 |\n",
      "|    explained_variance | 0.565     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -1.93e-08 |\n",
      "|    value_loss         | 0.0148    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 18.7      |\n",
      "|    ep_rew_mean        | 0.228     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2772      |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 370000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.96e-06 |\n",
      "|    explained_variance | 0.559     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -8.91e-09 |\n",
      "|    value_loss         | 0.0184    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.437     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2772      |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 135       |\n",
      "|    total_timesteps    | 375000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.96e-08 |\n",
      "|    explained_variance | -0.0147   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.428     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2769      |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 380000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.72e-06 |\n",
      "|    explained_variance | 0.151     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -1.72e-07 |\n",
      "|    value_loss         | 0.198     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.352     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2766      |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 385000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.57e-06 |\n",
      "|    explained_variance | 0.0672    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | -9.63e-08 |\n",
      "|    value_loss         | 0.187     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.418     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2763      |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 390000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.82e-06 |\n",
      "|    explained_variance | -0.00421  |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -1.18e-07 |\n",
      "|    value_loss         | 0.201     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.409     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2761      |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 395000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2e-05    |\n",
      "|    explained_variance | 0.13      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | -4.59e-07 |\n",
      "|    value_loss         | 0.172     |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.67 +/- 0.44\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 2         |\n",
      "|    mean_reward        | 0.665     |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 400000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.46e-06 |\n",
      "|    explained_variance | 0.255     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | -6.1e-08  |\n",
      "|    value_loss         | 0.114     |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2        |\n",
      "|    ep_rew_mean     | 0.675    |\n",
      "| time/              |          |\n",
      "|    fps             | 2757     |\n",
      "|    iterations      | 8000     |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 400000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.24      |\n",
      "|    ep_rew_mean        | 0.564     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2755      |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 405000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000262 |\n",
      "|    explained_variance | 0.0208    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 9.19e-06  |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2         |\n",
      "|    ep_rew_mean        | 0.618     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2751      |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 410000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.54e-05 |\n",
      "|    explained_variance | -0.0083   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.93e-06  |\n",
      "|    value_loss         | 0.192     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.1       |\n",
      "|    ep_rew_mean        | 0.558     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2750      |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 415000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000564 |\n",
      "|    explained_variance | 0.0362    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 1.79e-05  |\n",
      "|    value_loss         | 0.192     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.26      |\n",
      "|    ep_rew_mean        | 0.592     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2746      |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 420000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000296 |\n",
      "|    explained_variance | 0.0215    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 1e-05     |\n",
      "|    value_loss         | 0.177     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.1       |\n",
      "|    ep_rew_mean        | 0.52      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2742      |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 425000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000324 |\n",
      "|    explained_variance | 0.196     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 7.97e-06  |\n",
      "|    value_loss         | 0.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.24      |\n",
      "|    ep_rew_mean        | 0.545     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2740      |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 430000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000321 |\n",
      "|    explained_variance | 0.115     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 8.4e-06   |\n",
      "|    value_loss         | 0.148     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 16.6      |\n",
      "|    ep_rew_mean        | 0.18      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2743      |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 435000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.59e-05 |\n",
      "|    explained_variance | -1.56     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | -7.03e-08 |\n",
      "|    value_loss         | 0.00145   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 11.9      |\n",
      "|    ep_rew_mean        | 0.161     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2748      |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 440000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.37e-07 |\n",
      "|    explained_variance | -0.0393   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.000612  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 16.3      |\n",
      "|    ep_rew_mean        | 0.152     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2755      |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 445000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.46e-05 |\n",
      "|    explained_variance | -0.316    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -1.06e-07 |\n",
      "|    value_loss         | 0.00107   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 12.20 +/- 15.58\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 12.2      |\n",
      "|    mean_reward        | 0.38      |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 450000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00205  |\n",
      "|    explained_variance | -0.651    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -1.18e-05 |\n",
      "|    value_loss         | 0.0238    |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.2     |\n",
      "|    ep_rew_mean     | 0.352    |\n",
      "| time/              |          |\n",
      "|    fps             | 2757     |\n",
      "|    iterations      | 9000     |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 450000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.3       |\n",
      "|    ep_rew_mean        | 0.43      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2760      |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 455000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000151 |\n",
      "|    explained_variance | 0.0487    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 3.14e-06  |\n",
      "|    value_loss         | 0.185     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.18     |\n",
      "|    ep_rew_mean        | 0.67     |\n",
      "| time/                 |          |\n",
      "|    fps                | 2757     |\n",
      "|    iterations         | 9200     |\n",
      "|    time_elapsed       | 166      |\n",
      "|    total_timesteps    | 460000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00033 |\n",
      "|    explained_variance | 0.0976   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9199     |\n",
      "|    policy_loss        | 4.4e-06  |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.42      |\n",
      "|    ep_rew_mean        | 0.474     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2756      |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 465000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000148 |\n",
      "|    explained_variance | -0.0233   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 3.82e-06  |\n",
      "|    value_loss         | 0.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.44      |\n",
      "|    ep_rew_mean        | 0.654     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2752      |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 470000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000106 |\n",
      "|    explained_variance | 0.0491    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 2.97e-06  |\n",
      "|    value_loss         | 0.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 2.2       |\n",
      "|    ep_rew_mean        | 0.67      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2750      |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 475000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.000453 |\n",
      "|    explained_variance | -0.0399   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 1.84e-05  |\n",
      "|    value_loss         | 0.181     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 5.52      |\n",
      "|    ep_rew_mean        | 0.415     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2750      |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 480000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00031  |\n",
      "|    explained_variance | -1.56     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -1.25e-06 |\n",
      "|    value_loss         | 0.00662   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 26.8      |\n",
      "|    ep_rew_mean        | 0.14      |\n",
      "| time/                 |           |\n",
      "|    fps                | 2757      |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 485000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.12e-10 |\n",
      "|    explained_variance | -1.68     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.00108   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 28.4      |\n",
      "|    ep_rew_mean        | 0.103     |\n",
      "| time/                 |           |\n",
      "|    fps                | 2762      |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 490000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.27e-12 |\n",
      "|    explained_variance | -1.88     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.000646  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2763     |\n",
      "|    iterations         | 9900     |\n",
      "|    time_elapsed       | 179      |\n",
      "|    total_timesteps    | 495000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8e-15   |\n",
      "|    explained_variance | -1.28    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 9899     |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 0.000132 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 500000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.51e-14 |\n",
      "|    explained_variance | -0.954    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.16e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2765     |\n",
      "|    iterations      | 10000    |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 500000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2771      |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 505000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.09e-12 |\n",
      "|    explained_variance | 0.175     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.28e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2777      |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 510000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.34e-14 |\n",
      "|    explained_variance | -0.222    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 9.44e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2783      |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 185       |\n",
      "|    total_timesteps    | 515000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83e-10 |\n",
      "|    explained_variance | -0.188    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.65e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2790      |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 520000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.49e-12 |\n",
      "|    explained_variance | -1.24     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 9.39e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2796      |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 525000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.22e-15 |\n",
      "|    explained_variance | -0.018    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.55e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2801      |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 530000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.19e-12 |\n",
      "|    explained_variance | -0.503    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.78e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2807      |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 535000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09e-09 |\n",
      "|    explained_variance | -1.11     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.22e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2812      |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 191       |\n",
      "|    total_timesteps    | 540000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.32e-12 |\n",
      "|    explained_variance | -0.625    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.73e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2816      |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 193       |\n",
      "|    total_timesteps    | 545000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.08e-14 |\n",
      "|    explained_variance | -0.107    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.96e-05  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 550000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.75e-09 |\n",
      "|    explained_variance | -0.459    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.23e-07  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2789     |\n",
      "|    iterations      | 11000    |\n",
      "|    time_elapsed    | 197      |\n",
      "|    total_timesteps | 550000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2783      |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 199       |\n",
      "|    total_timesteps    | 555000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.01e-12 |\n",
      "|    explained_variance | -0.222    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.7e-07   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2778      |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 201       |\n",
      "|    total_timesteps    | 560000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.21e-12 |\n",
      "|    explained_variance | -0.155    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.87e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2778      |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 203       |\n",
      "|    total_timesteps    | 565000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46e-09 |\n",
      "|    explained_variance | -1.15     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.94e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2776      |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 205       |\n",
      "|    total_timesteps    | 570000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.71e-12 |\n",
      "|    explained_variance | -0.145    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.3e-06   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2776      |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 207       |\n",
      "|    total_timesteps    | 575000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.52e-10 |\n",
      "|    explained_variance | -0.649    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.00018   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2776      |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 208       |\n",
      "|    total_timesteps    | 580000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.64e-10 |\n",
      "|    explained_variance | -3.63     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.26e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2776      |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 210       |\n",
      "|    total_timesteps    | 585000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.35e-10 |\n",
      "|    explained_variance | -1.93     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.26e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2773      |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 212       |\n",
      "|    total_timesteps    | 590000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09e-09 |\n",
      "|    explained_variance | -0.479    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.97e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2774      |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 595000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.61e-12 |\n",
      "|    explained_variance | -0.109    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.000422  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 36       |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 600000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9e-10 |\n",
      "|    explained_variance | -0.524   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 11999    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 7.17e-08 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2769     |\n",
      "|    iterations      | 12000    |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 600000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2770      |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 218       |\n",
      "|    total_timesteps    | 605000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.64e-10 |\n",
      "|    explained_variance | -0.421    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.13e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2770      |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 220       |\n",
      "|    total_timesteps    | 610000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.81e-15 |\n",
      "|    explained_variance | -0.0774   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.79e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2773      |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 221       |\n",
      "|    total_timesteps    | 615000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.97e-15 |\n",
      "|    explained_variance | 0.0724    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.43e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2778      |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 223       |\n",
      "|    total_timesteps    | 620000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.36e-10 |\n",
      "|    explained_variance | -0.475    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.98e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2783      |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 224       |\n",
      "|    total_timesteps    | 625000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.94e-12 |\n",
      "|    explained_variance | -1.96     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.51e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2787      |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 226       |\n",
      "|    total_timesteps    | 630000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13e-15 |\n",
      "|    explained_variance | -0.226    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.08e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2791      |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 227       |\n",
      "|    total_timesteps    | 635000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47e-12 |\n",
      "|    explained_variance | -0.368    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.78e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2796      |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 228       |\n",
      "|    total_timesteps    | 640000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.59e-14 |\n",
      "|    explained_variance | -0.144    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.33e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2801     |\n",
      "|    iterations         | 12900    |\n",
      "|    time_elapsed       | 230      |\n",
      "|    total_timesteps    | 645000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.6e-12 |\n",
      "|    explained_variance | -1.56    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 12899    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.32e-08 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 650000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08e-14 |\n",
      "|    explained_variance | -0.486    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.51e-08  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2801     |\n",
      "|    iterations      | 13000    |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 650000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2804      |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 233       |\n",
      "|    total_timesteps    | 655000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.64e-13 |\n",
      "|    explained_variance | -0.438    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.17e-06  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2808     |\n",
      "|    iterations         | 13200    |\n",
      "|    time_elapsed       | 234      |\n",
      "|    total_timesteps    | 660000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.8e-14 |\n",
      "|    explained_variance | 0.116    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 13199    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 4.1e-08  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2813      |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 236       |\n",
      "|    total_timesteps    | 665000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.38e-10 |\n",
      "|    explained_variance | -0.445    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.7e-06   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2816      |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 237       |\n",
      "|    total_timesteps    | 670000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.09e-09 |\n",
      "|    explained_variance | -0.248    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.95e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2821      |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 675000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.24e-09 |\n",
      "|    explained_variance | -0.792    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.91e-05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2825      |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 240       |\n",
      "|    total_timesteps    | 680000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.83e-10 |\n",
      "|    explained_variance | -0.7      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.64e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2829      |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 685000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.39e-13 |\n",
      "|    explained_variance | -0.491    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.56e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2833      |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 243       |\n",
      "|    total_timesteps    | 690000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04e-14 |\n",
      "|    explained_variance | -0.373    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.68e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2837      |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 244       |\n",
      "|    total_timesteps    | 695000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.08e-12 |\n",
      "|    explained_variance | -0.219    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.17e-08  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 700000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.64e-14 |\n",
      "|    explained_variance | -0.0641   |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.39e-08  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2838     |\n",
      "|    iterations      | 14000    |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 700000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2842      |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 247       |\n",
      "|    total_timesteps    | 705000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45e-10 |\n",
      "|    explained_variance | -4.19     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.16e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2846      |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 249       |\n",
      "|    total_timesteps    | 710000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.97e-12 |\n",
      "|    explained_variance | -0.881    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.03e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2850     |\n",
      "|    iterations         | 14300    |\n",
      "|    time_elapsed       | 250      |\n",
      "|    total_timesteps    | 715000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.8e-10 |\n",
      "|    explained_variance | -0.588   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14299    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.56e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2854      |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 252       |\n",
      "|    total_timesteps    | 720000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.49e-12 |\n",
      "|    explained_variance | -0.785    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.42e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2857      |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 253       |\n",
      "|    total_timesteps    | 725000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85e-12 |\n",
      "|    explained_variance | -0.148    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.03e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2861      |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 255       |\n",
      "|    total_timesteps    | 730000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.23e-13 |\n",
      "|    explained_variance | -0.411    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.1e-08   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2865      |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 735000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.43e-10 |\n",
      "|    explained_variance | -0.808    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.94e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2868      |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 257       |\n",
      "|    total_timesteps    | 740000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.88e-10 |\n",
      "|    explained_variance | -0.421    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.38e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2871     |\n",
      "|    iterations         | 14900    |\n",
      "|    time_elapsed       | 259      |\n",
      "|    total_timesteps    | 745000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9e-10 |\n",
      "|    explained_variance | -0.406   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 14899    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.13e-08 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 750000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.09e-10 |\n",
      "|    explained_variance | -1.04     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.18e-08  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2869     |\n",
      "|    iterations      | 15000    |\n",
      "|    time_elapsed    | 261      |\n",
      "|    total_timesteps | 750000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2872      |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 262       |\n",
      "|    total_timesteps    | 755000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.26e-12 |\n",
      "|    explained_variance | -0.525    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.97e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2875     |\n",
      "|    iterations         | 15200    |\n",
      "|    time_elapsed       | 264      |\n",
      "|    total_timesteps    | 760000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.4e-12 |\n",
      "|    explained_variance | -2.36    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 3.35e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2879      |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 265       |\n",
      "|    total_timesteps    | 765000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.46e-09 |\n",
      "|    explained_variance | -0.663    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.88e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2882      |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 267       |\n",
      "|    total_timesteps    | 770000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.48e-15 |\n",
      "|    explained_variance | -0.574    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 9.62e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2880      |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 775000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.43e-12 |\n",
      "|    explained_variance | -0.531    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.6e-05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2880     |\n",
      "|    iterations         | 15600    |\n",
      "|    time_elapsed       | 270      |\n",
      "|    total_timesteps    | 780000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.6e-10 |\n",
      "|    explained_variance | -0.354   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15599    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.01e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2877      |\n",
      "|    iterations         | 15700     |\n",
      "|    time_elapsed       | 272       |\n",
      "|    total_timesteps    | 785000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.75e-14 |\n",
      "|    explained_variance | -1.32     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.33e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2880     |\n",
      "|    iterations         | 15800    |\n",
      "|    time_elapsed       | 274      |\n",
      "|    total_timesteps    | 790000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.3e-10 |\n",
      "|    explained_variance | -0.709   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15799    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 6.45e-07 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2883      |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 275       |\n",
      "|    total_timesteps    | 795000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.66e-10 |\n",
      "|    explained_variance | -0.116    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.76e-06  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 36       |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 800000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.4e-14 |\n",
      "|    explained_variance | 0.178    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 15999    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.27e-09 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2884     |\n",
      "|    iterations      | 16000    |\n",
      "|    time_elapsed    | 277      |\n",
      "|    total_timesteps | 800000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2887      |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 278       |\n",
      "|    total_timesteps    | 805000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.67e-12 |\n",
      "|    explained_variance | -1.82     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.99e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2891     |\n",
      "|    iterations         | 16200    |\n",
      "|    time_elapsed       | 280      |\n",
      "|    total_timesteps    | 810000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9e-10 |\n",
      "|    explained_variance | -0.0297  |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 16199    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.11e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2894      |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 281       |\n",
      "|    total_timesteps    | 815000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.66e-10 |\n",
      "|    explained_variance | -0.143    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.24e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2897      |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 282       |\n",
      "|    total_timesteps    | 820000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.81e-10 |\n",
      "|    explained_variance | -0.634    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.42e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2900      |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 284       |\n",
      "|    total_timesteps    | 825000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.91e-10 |\n",
      "|    explained_variance | -0.624    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.07e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2903      |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 285       |\n",
      "|    total_timesteps    | 830000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45e-10 |\n",
      "|    explained_variance | 0.0486    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.83e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2906      |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 287       |\n",
      "|    total_timesteps    | 835000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.28e-10 |\n",
      "|    explained_variance | -0.114    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 9.95e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2909     |\n",
      "|    iterations         | 16800    |\n",
      "|    time_elapsed       | 288      |\n",
      "|    total_timesteps    | 840000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9e-10 |\n",
      "|    explained_variance | -7.36    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 16799    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.03e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2912      |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 290       |\n",
      "|    total_timesteps    | 845000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.31e-13 |\n",
      "|    explained_variance | -0.343    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.34e-08  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 850000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.65e-14 |\n",
      "|    explained_variance | -4.5      |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.57e-07  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2913     |\n",
      "|    iterations      | 17000    |\n",
      "|    time_elapsed    | 291      |\n",
      "|    total_timesteps | 850000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2916      |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 293       |\n",
      "|    total_timesteps    | 855000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.86e-13 |\n",
      "|    explained_variance | -0.309    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.21e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2917      |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 294       |\n",
      "|    total_timesteps    | 860000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.48e-13 |\n",
      "|    explained_variance | -0.339    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.58e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2920      |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 296       |\n",
      "|    total_timesteps    | 865000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.89e-12 |\n",
      "|    explained_variance | 0.0258    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.55e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2923      |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 297       |\n",
      "|    total_timesteps    | 870000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.71e-12 |\n",
      "|    explained_variance | 0.192     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.34e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2926      |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 299       |\n",
      "|    total_timesteps    | 875000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.08e-14 |\n",
      "|    explained_variance | -0.663    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.9e-09   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2928      |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 300       |\n",
      "|    total_timesteps    | 880000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.99e-12 |\n",
      "|    explained_variance | -0.451    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.57e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2931      |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 301       |\n",
      "|    total_timesteps    | 885000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.64e-10 |\n",
      "|    explained_variance | -0.105    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 0.000105  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2934      |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 303       |\n",
      "|    total_timesteps    | 890000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96e-12 |\n",
      "|    explained_variance | -0.163    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.26e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2937     |\n",
      "|    iterations         | 17900    |\n",
      "|    time_elapsed       | 304      |\n",
      "|    total_timesteps    | 895000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.8e-10 |\n",
      "|    explained_variance | -12.2    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17899    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.97e-07 |\n",
      "------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "------------------------------------\n",
      "| eval/                 |          |\n",
      "|    mean_ep_length     | 36       |\n",
      "|    mean_reward        | 0        |\n",
      "| time/                 |          |\n",
      "|    total_timesteps    | 900000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -2.9e-10 |\n",
      "|    explained_variance | -0.991   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 17999    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 6.66e-09 |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2938     |\n",
      "|    iterations      | 18000    |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 900000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2941      |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 307       |\n",
      "|    total_timesteps    | 905000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53e-09 |\n",
      "|    explained_variance | -1.32     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 5.37e-07  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2943     |\n",
      "|    iterations         | 18200    |\n",
      "|    time_elapsed       | 309      |\n",
      "|    total_timesteps    | 910000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.6e-14 |\n",
      "|    explained_variance | -0.208   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 18199    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 1.28e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2946     |\n",
      "|    iterations         | 18300    |\n",
      "|    time_elapsed       | 310      |\n",
      "|    total_timesteps    | 915000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.8e-10 |\n",
      "|    explained_variance | -0.113   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 18299    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 6.91e-09 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2948      |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 312       |\n",
      "|    total_timesteps    | 920000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.85e-12 |\n",
      "|    explained_variance | -0.752    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.23e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2951      |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 313       |\n",
      "|    total_timesteps    | 925000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.67e-14 |\n",
      "|    explained_variance | -0.567    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.75e-08  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2953      |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 314       |\n",
      "|    total_timesteps    | 930000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.32e-15 |\n",
      "|    explained_variance | -20.7     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.89e-10  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2956      |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 316       |\n",
      "|    total_timesteps    | 935000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.37e-12 |\n",
      "|    explained_variance | 0.155     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.65e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2958      |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 317       |\n",
      "|    total_timesteps    | 940000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.23e-12 |\n",
      "|    explained_variance | -0.601    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.23e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2954      |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 319       |\n",
      "|    total_timesteps    | 945000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.95e-12 |\n",
      "|    explained_variance | -1.81     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 4.87e-07  |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 950000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.45e-14 |\n",
      "|    explained_variance | -0.294    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 3.55e-08  |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2952     |\n",
      "|    iterations      | 19000    |\n",
      "|    time_elapsed    | 321      |\n",
      "|    total_timesteps | 950000   |\n",
      "---------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2949      |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 323       |\n",
      "|    total_timesteps    | 955000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.35e-10 |\n",
      "|    explained_variance | 0.0949    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.95e-07  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2950      |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 960000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.95e-12 |\n",
      "|    explained_variance | -0.148    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.25e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2951      |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 326       |\n",
      "|    total_timesteps    | 965000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.49e-12 |\n",
      "|    explained_variance | -0.683    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.81e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2952      |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 328       |\n",
      "|    total_timesteps    | 970000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.38e-13 |\n",
      "|    explained_variance | -0.506    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 1.09e-06  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2951      |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 330       |\n",
      "|    total_timesteps    | 975000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.47e-12 |\n",
      "|    explained_variance | -3        |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 6.08e-09  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2950     |\n",
      "|    iterations         | 19600    |\n",
      "|    time_elapsed       | 332      |\n",
      "|    total_timesteps    | 980000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.5e-10 |\n",
      "|    explained_variance | -0.573   |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19599    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 6.75e-06 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 36       |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 2951     |\n",
      "|    iterations         | 19700    |\n",
      "|    time_elapsed       | 333      |\n",
      "|    total_timesteps    | 985000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.1e-09 |\n",
      "|    explained_variance | -1.14    |\n",
      "|    learning_rate      | 0.002    |\n",
      "|    n_updates          | 19699    |\n",
      "|    policy_loss        | -0       |\n",
      "|    value_loss         | 4.83e-08 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2954      |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 335       |\n",
      "|    total_timesteps    | 990000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.96e-12 |\n",
      "|    explained_variance | -1.13     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 7.16e-09  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 36        |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 2956      |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 336       |\n",
      "|    total_timesteps    | 995000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.44e-14 |\n",
      "|    explained_variance | -0.669    |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 2.4e-08   |\n",
      "-------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 36.00 +/- 0.00\n",
      "-------------------------------------\n",
      "| eval/                 |           |\n",
      "|    mean_ep_length     | 36        |\n",
      "|    mean_reward        | 0         |\n",
      "| time/                 |           |\n",
      "|    total_timesteps    | 1000000   |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.25e-14 |\n",
      "|    explained_variance | -0.38     |\n",
      "|    learning_rate      | 0.002     |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | -0        |\n",
      "|    value_loss         | 8.8e-09   |\n",
      "-------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36       |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 2956     |\n",
      "|    iterations      | 20000    |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 1000000  |\n",
      "---------------------------------\n",
      "Using cpu device\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.6     |\n",
      "|    ep_rew_mean     | 0.265    |\n",
      "| time/              |          |\n",
      "|    fps             | 3627     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 13.9        |\n",
      "|    ep_rew_mean          | 0.337       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1796        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011490433 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.00342    |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.0508      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013521438 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.00938     |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.000819   |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0647      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.2      |\n",
      "|    ep_rew_mean     | 0.372    |\n",
      "| time/              |          |\n",
      "|    fps             | 1549     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 8.8        |\n",
      "|    ep_rew_mean          | 0.335      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1448       |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 56         |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01155234 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.00256    |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.00241   |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    value_loss           | 0.0786     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.57 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009976997 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.00285     |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0257      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 6.45     |\n",
      "|    ep_rew_mean     | 0.404    |\n",
      "| time/              |          |\n",
      "|    fps             | 1391     |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 102400   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5.65         |\n",
      "|    ep_rew_mean          | 0.399        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092089875 |\n",
      "|    clip_fraction        | 0.0843       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.0064       |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0373       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 4.46         |\n",
      "|    ep_rew_mean          | 0.486        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1322         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097279055 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.0121       |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0561       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00889     |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=0.47 +/- 0.48\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.475       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011814531 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.32     |\n",
      "|    ep_rew_mean     | 0.396    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 8        |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 163840   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.06        |\n",
      "|    ep_rew_mean          | 0.471       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1288        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011910884 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.0143      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.38        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010780089 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.09     |\n",
      "|    ep_rew_mean     | 0.462    |\n",
      "| time/              |          |\n",
      "|    fps             | 1276     |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 204800   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.93        |\n",
      "|    ep_rew_mean          | 0.44        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1266        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009768148 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0588      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.87         |\n",
      "|    ep_rew_mean          | 0.557        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1256         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074840277 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.00616      |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0575       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 0.179        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0.38       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 250000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00530977 |\n",
      "|    clip_fraction        | 0.0593     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.00699    |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0831     |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00113   |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.75     |\n",
      "|    ep_rew_mean     | 0.586    |\n",
      "| time/              |          |\n",
      "|    fps             | 1247     |\n",
      "|    iterations      | 13       |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 266240   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.47         |\n",
      "|    ep_rew_mean          | 0.489        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1240         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041149245 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.00253      |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0874       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -5.15e-05    |\n",
      "|    value_loss           | 0.186        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.57 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.57        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005823045 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0952      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51     |\n",
      "|    ep_rew_mean     | 0.498    |\n",
      "| time/              |          |\n",
      "|    fps             | 1234     |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 248      |\n",
      "|    total_timesteps | 307200   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.48         |\n",
      "|    ep_rew_mean          | 0.439        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1229         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041624503 |\n",
      "|    clip_fraction        | 0.0506       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.923       |\n",
      "|    explained_variance   | 0.0595       |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0688       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.000741    |\n",
      "|    value_loss           | 0.172        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.37        |\n",
      "|    ep_rew_mean          | 0.564       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1224        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 284         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004913818 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0764      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -5.55e-05   |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.67 +/- 0.44\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.665       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005490169 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0829      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.45     |\n",
      "|    ep_rew_mean     | 0.562    |\n",
      "| time/              |          |\n",
      "|    fps             | 1220     |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 302      |\n",
      "|    total_timesteps | 368640   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.19       |\n",
      "|    ep_rew_mean          | 0.501      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1217       |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 319        |\n",
      "|    total_timesteps      | 389120     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00517593 |\n",
      "|    clip_fraction        | 0.069      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.731     |\n",
      "|    explained_variance   | 0.192      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0854     |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.00293   |\n",
      "|    value_loss           | 0.153      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.57 +/- 0.47\n",
      "Episode length: 2.20 +/- 0.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.2          |\n",
      "|    mean_reward          | 0.57         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058709444 |\n",
      "|    clip_fraction        | 0.0839       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.653       |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0728       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 0.154        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35     |\n",
      "|    ep_rew_mean     | 0.506    |\n",
      "| time/              |          |\n",
      "|    fps             | 1200     |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 341      |\n",
      "|    total_timesteps | 409600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52        |\n",
      "|    ep_rew_mean          | 0.596       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1195        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006170424 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=0.47 +/- 0.48\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.475       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004785522 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0617      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41     |\n",
      "|    ep_rew_mean     | 0.543    |\n",
      "| time/              |          |\n",
      "|    fps             | 1193     |\n",
      "|    iterations      | 22       |\n",
      "|    time_elapsed    | 377      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.15       |\n",
      "|    ep_rew_mean          | 0.548      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1188       |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 396        |\n",
      "|    total_timesteps      | 471040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14364855 |\n",
      "|    clip_fraction        | 0.048      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.477     |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0427     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | 0.0426     |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.37       |\n",
      "|    ep_rew_mean          | 0.486      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1184       |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 415        |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15452704 |\n",
      "|    clip_fraction        | 0.086      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.437     |\n",
      "|    explained_variance   | 0.0463     |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | 0.0446     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | 0.0182     |\n",
      "|    value_loss           | 0.153      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2            |\n",
      "|    mean_reward          | 0.38         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 500000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058636726 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0462       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -9.37e-05    |\n",
      "|    value_loss           | 0.12         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.55     |\n",
      "|    ep_rew_mean     | 0.605    |\n",
      "| time/              |          |\n",
      "|    fps             | 1181     |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 512000   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18         |\n",
      "|    ep_rew_mean          | 0.556        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1180         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 451          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032784087 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0569       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=550000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 5.40 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5.4         |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004529643 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.374      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.16     |\n",
      "|    ep_rew_mean     | 0.605    |\n",
      "| time/              |          |\n",
      "|    fps             | 1176     |\n",
      "|    iterations      | 27       |\n",
      "|    time_elapsed    | 469      |\n",
      "|    total_timesteps | 552960   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.2          |\n",
      "|    ep_rew_mean          | 0.557        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1174         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 488          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067292363 |\n",
      "|    clip_fraction        | 0.0734       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | 0.0423       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 0.103        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14        |\n",
      "|    ep_rew_mean          | 0.568       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1172        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 506         |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008883479 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.272      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 0.0986      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 2.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2           |\n",
      "|    mean_reward          | 0.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009340668 |\n",
      "|    clip_fraction        | 0.0368      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.226      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00804     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 0.0676      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.11     |\n",
      "|    ep_rew_mean     | 0.493    |\n",
      "| time/              |          |\n",
      "|    fps             | 1171     |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 524      |\n",
      "|    total_timesteps | 614400   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.06         |\n",
      "|    ep_rew_mean          | 0.512        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1169         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 542          |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062817507 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.202       |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.002        |\n",
      "|    loss                 | -0.00129     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 9.63e-05     |\n",
      "|    value_loss           | 0.0312       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.28 +/- 0.44\n",
      "Episode length: 5.40 +/- 10.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5.4        |\n",
      "|    mean_reward          | 0.285      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 650000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50409615 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0169    |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | 0.0803     |\n",
      "|    value_loss           | 0.00208    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.4      |\n",
      "|    ep_rew_mean     | 0.407    |\n",
      "| time/              |          |\n",
      "|    fps             | 1169     |\n",
      "|    iterations      | 32       |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 655360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77        |\n",
      "|    ep_rew_mean          | 0.536       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1167        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 675840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.106862485 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.291      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0764     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 0.0208      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.05       |\n",
      "|    ep_rew_mean          | 0.432      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1164       |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 597        |\n",
      "|    total_timesteps      | 696320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20822665 |\n",
      "|    clip_fraction        | 0.559      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.497     |\n",
      "|    explained_variance   | 0.813      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0722    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | 0.0124     |\n",
      "|    value_loss           | 0.0151     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.47 +/- 0.48\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0.475      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 700000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13910289 |\n",
      "|    clip_fraction        | 0.442      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | 0.881      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0801    |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.127      |\n",
      "|    value_loss           | 0.00843    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.26     |\n",
      "|    ep_rew_mean     | 0.546    |\n",
      "| time/              |          |\n",
      "|    fps             | 1164     |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 615      |\n",
      "|    total_timesteps | 716800   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 3.28      |\n",
      "|    ep_rew_mean          | 0.552     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1162      |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 634       |\n",
      "|    total_timesteps      | 737280    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5454913 |\n",
      "|    clip_fraction        | 0.422     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.792    |\n",
      "|    explained_variance   | 0.941     |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0726   |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -0.0357   |\n",
      "|    value_loss           | 0.00745   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=0.57 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0.57       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 750000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02427306 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.718     |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0408    |\n",
      "|    value_loss           | 0.00495    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.64     |\n",
      "|    ep_rew_mean     | 0.641    |\n",
      "| time/              |          |\n",
      "|    fps             | 1154     |\n",
      "|    iterations      | 37       |\n",
      "|    time_elapsed    | 656      |\n",
      "|    total_timesteps | 757760   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.37       |\n",
      "|    ep_rew_mean          | 0.518      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1146       |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 678        |\n",
      "|    total_timesteps      | 778240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02870366 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.488     |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0542    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0452    |\n",
      "|    value_loss           | 0.0022     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17        |\n",
      "|    ep_rew_mean          | 0.577       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1143        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033553876 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0398     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.001       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.38 +/- 0.47\n",
      "Episode length: 2.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2          |\n",
      "|    mean_reward          | 0.38       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 800000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15791544 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.21      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.041     |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | 0.109      |\n",
      "|    value_loss           | 0.000893   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.04     |\n",
      "|    ep_rew_mean     | 0.627    |\n",
      "| time/              |          |\n",
      "|    fps             | 1140     |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 718      |\n",
      "|    total_timesteps | 819200   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01        |\n",
      "|    ep_rew_mean          | 0.523       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1138        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 737         |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035095077 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.128      |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0356     |\n",
      "|    value_loss           | 0.0231      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.28 +/- 0.44\n",
      "Episode length: 12.20 +/- 15.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 12.2       |\n",
      "|    mean_reward          | 0.285      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 850000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06964813 |\n",
      "|    clip_fraction        | 0.0976     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.101     |\n",
      "|    explained_variance   | 0.909      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0142    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0305    |\n",
      "|    value_loss           | 0.0158     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.86     |\n",
      "|    ep_rew_mean     | 0.582    |\n",
      "| time/              |          |\n",
      "|    fps             | 1138     |\n",
      "|    iterations      | 42       |\n",
      "|    time_elapsed    | 755      |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 5.78      |\n",
      "|    ep_rew_mean          | 0.518     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1139      |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 772       |\n",
      "|    total_timesteps      | 880640    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1938977 |\n",
      "|    clip_fraction        | 0.369     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.32     |\n",
      "|    explained_variance   | 0.573     |\n",
      "|    learning_rate        | 0.002     |\n",
      "|    loss                 | -0.0735   |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -0.0308   |\n",
      "|    value_loss           | 0.0318    |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 15.60 +/- 16.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 15.6        |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.111576416 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.00289     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.03     |\n",
      "|    ep_rew_mean     | 0.686    |\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 790      |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.85        |\n",
      "|    ep_rew_mean          | 0.693       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1139        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 809         |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019874012 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0131      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.0176      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.7        |\n",
      "|    ep_rew_mean          | 0.641      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1139       |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 827        |\n",
      "|    total_timesteps      | 942080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07328469 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.56      |\n",
      "|    explained_variance   | 0.858      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0246    |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    value_loss           | 0.0165     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.19 +/- 0.38\n",
      "Episode length: 22.40 +/- 16.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 22.4       |\n",
      "|    mean_reward          | 0.19       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 950000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39599466 |\n",
      "|    clip_fraction        | 0.435      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.733     |\n",
      "|    explained_variance   | 0.908      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0239    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0328    |\n",
      "|    value_loss           | 0.0123     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.28     |\n",
      "|    ep_rew_mean     | 0.551    |\n",
      "| time/              |          |\n",
      "|    fps             | 1139     |\n",
      "|    iterations      | 47       |\n",
      "|    time_elapsed    | 844      |\n",
      "|    total_timesteps | 962560   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 7.12       |\n",
      "|    ep_rew_mean          | 0.621      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1140       |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 861        |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08605019 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.678     |\n",
      "|    explained_variance   | 0.611      |\n",
      "|    learning_rate        | 0.002      |\n",
      "|    loss                 | -0.0101    |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.000826  |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.10 +/- 0.28\n",
      "Episode length: 19.00 +/- 17.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 19          |\n",
      "|    mean_reward          | 0.095       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052003168 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.002       |\n",
      "|    loss                 | 0.0132      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.0172      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.77     |\n",
      "|    ep_rew_mean     | 0.597    |\n",
      "| time/              |          |\n",
      "|    fps             | 1141     |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 879      |\n",
      "|    total_timesteps | 1003520  |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "N_ENVS = 10\n",
    "N_EVALS = 20\n",
    "N_BASE_STEPS = 100000\n",
    "N_TOTAL_STEPS = N_BASE_STEPS * N_ENVS\n",
    "N_EVAL_EPISODES = 10\n",
    "\n",
    "ENV_ID = 'MiniGrid-NumberTasksNosePoke-v0'\n",
    "TRAIN_SEED = 100\n",
    "EVAL_SEED = 200\n",
    "\n",
    "TASKS = NumberTaskType\n",
    "\n",
    "AGENT_TYPES = [A2C, PPO]\n",
    "AGENT_KWARGS = dict(learning_rate=2e-3)\n",
    "\n",
    "all_agent_results = defaultdict(dict)\n",
    "\n",
    "\n",
    "for task in TASKS:\n",
    "    for agent_type in AGENT_TYPES:\n",
    "        if N_ENVS == 1:\n",
    "            env = _make_env(ENV_ID, seed=TRAIN_SEED, task=task)\n",
    "        else:\n",
    "            env = _make_n_envs(ENV_ID, n=N_ENVS, seed=TRAIN_SEED, task=task)\n",
    "\n",
    "        eval_env =_make_env(ENV_ID, seed=EVAL_SEED, task=task)\n",
    "        stop_callback = StopTrainingOnRewardThreshold(reward_threshold=0.85, verbose=1)\n",
    "        eval_callback = EvalCallback(eval_env, n_eval_episodes=N_EVAL_EPISODES, \n",
    "            eval_freq=N_BASE_STEPS / N_EVALS, callback_on_new_best=stop_callback,\n",
    "            log_path=f'./logs/{agent_type.__name__}_{task.name}', verbose=1)\n",
    "\n",
    "        model = agent_type('MlpPolicy', env, verbose=1, **AGENT_KWARGS)\n",
    "        model.learn(total_timesteps=N_TOTAL_STEPS, callback=eval_callback)\n",
    "\n",
    "        rewards = eval_callback.evaluations_results\n",
    "        means = [np.mean(r) for r in rewards]\n",
    "        stds = [np.std(r) for r in rewards]\n",
    "\n",
    "        all_agent_results[task.name][agent_type.__name__] = means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color A2C [0.0, 0.5700000000000001, 0.9200000000000002]\n",
      "color PPO [0.665, 0.9499999999999998]\n",
      "magnitude A2C [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19, 0.0, 0.095, 0.095, 0.0, 0.0, 0.0, 0.0, 0.095, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "magnitude PPO [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "parity A2C [0.38, 0.475, 0.47000000000000003, 0.475, 0.655, 0.38, 0.665, 0.665, 0.38, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "parity PPO [0.38, 0.5700000000000001, 0.475, 0.38, 0.38, 0.5700000000000001, 0.665, 0.5700000000000001, 0.475, 0.38, 0.19, 0.19, 0.285, 0.475, 0.5700000000000001, 0.38, 0.285, 0.0, 0.19, 0.095]\n"
     ]
    }
   ],
   "source": [
    "for task_name, agent_results in all_agent_results.items():\n",
    "    for agent, results in agent_results.items():\n",
    "        means, stds = results\n",
    "        print(task_name, agent, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2,  5,  0],\n",
       "        [ 2,  5,  0],\n",
       "        [ 8,  1,  0]],\n",
       "\n",
       "       [[ 2,  5,  0],\n",
       "        [11,  1,  5],\n",
       "        [ 1,  0,  0]],\n",
       "\n",
       "       [[ 2,  5,  0],\n",
       "        [ 2,  5,  0],\n",
       "        [ 8,  1,  0]]], dtype=uint8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = _make_env(ENV_ID, seed=TRAIN_SEED, task='color')\n",
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 2,  5,  0],\n",
       "         [ 2,  5,  0],\n",
       "         [11,  1,  5]],\n",
       " \n",
       "        [[ 6,  2,  0],\n",
       "         [ 8,  1,  0],\n",
       "         [ 1,  0,  0]],\n",
       " \n",
       "        [[ 2,  5,  0],\n",
       "         [ 2,  5,  0],\n",
       "         [ 2,  5,  0]]], dtype=uint8),\n",
       " 0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.actions.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[ 2,  5,  0],\n",
       "         [ 2,  5,  0],\n",
       "         [ 2,  5,  0]],\n",
       " \n",
       "        [[11,  5,  0],\n",
       "         [ 8,  1,  0],\n",
       "         [ 1,  0,  0]],\n",
       " \n",
       "        [[ 2,  5,  0],\n",
       "         [ 2,  5,  0],\n",
       "         [11,  1,  5]]], dtype=uint8),\n",
       " 0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.actions.left)\n",
    "env.step(env.actions.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 0.9, 0.95, 0.95, 0.9, 0.9, 0.9, 0.95, 0.9, 0.95]\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 10\n",
    "\n",
    "env = _make_env(ENV_ID, seed=TRAIN_SEED, task='parity')\n",
    "rewards = []\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    obs = env.reset()\n",
    "    digit = obs[1, 1, -1]\n",
    "    turn_obs, _, _, _ = env.step(env.actions.left)\n",
    "    task_marker = turn_obs[1, 0, -1]\n",
    "\n",
    "    if (digit % 2) != task_marker:\n",
    "        env.step(env.actions.left)\n",
    "        env.step(env.actions.left)\n",
    "\n",
    "    _, r, done, _ = env.step(env.actions.forward)\n",
    "    if not done:\n",
    "        raise ValueError('Expected done')\n",
    "    rewards.append(r)\n",
    "\n",
    "print(rewards)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 0.9, 0.9, 0.9, 0.95, 0.95, 0.9, 0.9, 0.9, 0.9]\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 10\n",
    "\n",
    "env = _make_env(ENV_ID, seed=TRAIN_SEED, task='magnitude')\n",
    "rewards = []\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    obs = env.reset()\n",
    "    digit = obs[1, 1, -1]\n",
    "    turn_obs, _, _, _ = env.step(env.actions.left)\n",
    "    task_marker = turn_obs[1, 0, -1]\n",
    "\n",
    "    if (digit >= 5) != (task_marker == 11):\n",
    "        env.step(env.actions.left)\n",
    "        env.step(env.actions.left)\n",
    "\n",
    "    _, r, done, _ = env.step(env.actions.forward)\n",
    "    if not done:\n",
    "        raise ValueError('Expected done')\n",
    "    rewards.append(r)\n",
    "\n",
    "print(rewards)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95, 0.95, 0.9, 0.9, 0.9, 0.9, 0.95, 0.95, 0.95, 0.95]\n"
     ]
    }
   ],
   "source": [
    "N_ITER = 10\n",
    "\n",
    "env = _make_env(ENV_ID, seed=TRAIN_SEED, task='color')\n",
    "rewards = []\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    obs = env.reset()\n",
    "    digit_color = obs[1, 1, 1]\n",
    "    turn_obs, _, _, _ = env.step(env.actions.left)\n",
    "    task_color = turn_obs[1, 0, 1]\n",
    "\n",
    "    if digit_color != task_color:\n",
    "        env.step(env.actions.left)\n",
    "        env.step(env.actions.left)\n",
    "\n",
    "    _, r, done, _ = env.step(env.actions.forward)\n",
    "    if not done:\n",
    "        raise ValueError('Expected done')\n",
    "    rewards.append(r)\n",
    "\n",
    "print(rewards)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8775025b178470b7b487df744aa50e287915f8de1ad29ac834985f09f2d3ff0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('minigrid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
